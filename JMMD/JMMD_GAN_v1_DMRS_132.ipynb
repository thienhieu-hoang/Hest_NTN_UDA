{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465b0cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# import utils\n",
    "# import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5df69823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thien/Code/NTN/Hest_NTN_UDA/JMMD\n",
      "/home/thien/Code/NTN/Hest_NTN_UDA\n"
     ]
    }
   ],
   "source": [
    "# Add the root project directory\n",
    "notebook_dir = os.getcwd()\n",
    "root_dir = os.path.abspath(os.path.join(notebook_dir, '..'))\n",
    "sys.path.insert(0, root_dir)\n",
    "print(notebook_dir)\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403ed309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Domain_Adversarial.helper import loader, plotfig, PAD\n",
    "from Domain_Adversarial.helper.utils import minmaxScaler, complx2real, H5BatchLoader, deMinMax\n",
    "from Domain_Adversarial.helper.utils_GAN import visualize_H, post_val\n",
    "from Domain_Adversarial.helper.utils_GAN import save_checkpoint_ as save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ed0a4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8588be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a (16, 792, 14, 2) matrix with random values\n",
    "# random_matrix = np.random.randn(16, 132, 14, 2)\n",
    "# random_matrix.shape\n",
    "\n",
    "# GAN_model = utils_GAN.GAN(n_subc=132)\n",
    "# out_put = GAN_model(random_matrix)\n",
    "# print(out_put.gen_out.shape)\n",
    "# print(out_put.disc_out.shape)\n",
    "# print(out_put.extracted_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c4d04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model, optimizers, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656ba055",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0003f5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class train_step_Output:\n",
    "    \"\"\"Dataclass to hold the output of the train_step function.\"\"\"\n",
    "    avg_epoc_loss_est: float  # Average loss for generator \n",
    "    avg_epoc_loss_d: float  # Average loss for discriminator \n",
    "    avg_epoc_loss_domain: float\n",
    "    avg_epoc_loss: float\n",
    "    avg_epoc_loss_est_target: float  # Average loss for channel estimation on target domain\n",
    "    features_source: tf.Tensor = None  # Features from the source domain, if return_features is True\n",
    "    film_features_source: tf.Tensor = None  # Film features from the source domain, if return_features is True\n",
    "    features_target: tf.Tensor = None  # Features from the target domain, if return_features is True\n",
    "    film_features_target: tf.Tensor = None  # Film features from the target domain, if return_features is True\n",
    "    pad: float = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fe3385",
   "metadata": {},
   "source": [
    "## JMMD Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fa9114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JMMDLoss(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Joint Maximum Mean Discrepancy Loss in TensorFlow\n",
    "    Computes JMMD across multiple feature layers\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_type='rbf', kernel_mul=2.0, kernel_num=5, fix_sigma=None, **kwargs):\n",
    "        super(JMMDLoss, self).__init__(**kwargs)\n",
    "        self.kernel_type = kernel_type\n",
    "        self.kernel_mul = kernel_mul\n",
    "        self.kernel_num = kernel_num\n",
    "        self.fix_sigma = fix_sigma\n",
    "    \n",
    "    def gaussian_kernel(self, source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        \"\"\"\n",
    "        Compute Gaussian kernel matrix\n",
    "        \"\"\"\n",
    "        n_samples = tf.shape(source)[0] + tf.shape(target)[0]\n",
    "        total = tf.concat([source, target], axis=0)\n",
    "        \n",
    "        # Compute pairwise distances\n",
    "        total_expanded_1 = tf.expand_dims(total, 1)  # [n, 1, d]\n",
    "        total_expanded_2 = tf.expand_dims(total, 0)  # [1, n, d]\n",
    "        \n",
    "        L2_distance = tf.reduce_sum(tf.square(total_expanded_1 - total_expanded_2), axis=2)\n",
    "        \n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = tf.reduce_sum(L2_distance) / tf.cast(n_samples ** 2 - n_samples, tf.float32)\n",
    "        \n",
    "        bandwidth = bandwidth / (kernel_mul ** (kernel_num // 2))\n",
    "        bandwidth_list = [bandwidth * (kernel_mul ** i) for i in range(kernel_num)]\n",
    "        \n",
    "        kernel_val = [tf.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "        return tf.reduce_sum(kernel_val, axis=0)\n",
    "    \n",
    "    def mmd(self, source, target):\n",
    "        \"\"\"\n",
    "        Compute MMD between source and target\n",
    "        \"\"\"\n",
    "        batch_size = tf.shape(source)[0]\n",
    "        kernels = self.gaussian_kernel(source, target, \n",
    "                                    kernel_mul=self.kernel_mul, \n",
    "                                    kernel_num=self.kernel_num, \n",
    "                                    fix_sigma=self.fix_sigma)\n",
    "        \n",
    "        XX = kernels[:batch_size, :batch_size]\n",
    "        YY = kernels[batch_size:, batch_size:]\n",
    "        XY = kernels[:batch_size, batch_size:]\n",
    "        YX = kernels[batch_size:, :batch_size]\n",
    "        \n",
    "        loss = tf.reduce_mean(XX + YY - XY - YX)\n",
    "        return loss\n",
    "    \n",
    "    def call(self, source_list, target_list):\n",
    "        \"\"\"\n",
    "        Compute JMMD across multiple layers\n",
    "        source_list: list of source features from different layers\n",
    "        target_list: list of target features from different layers\n",
    "        \"\"\"\n",
    "        jmmd_loss = 0.0\n",
    "        for source_feat, target_feat in zip(source_list, target_list):\n",
    "            # Flatten features if needed\n",
    "            if len(source_feat.shape) > 2:\n",
    "                source_feat = tf.reshape(source_feat, [tf.shape(source_feat)[0], -1])\n",
    "                target_feat = tf.reshape(target_feat, [tf.shape(target_feat)[0], -1])\n",
    "            \n",
    "            jmmd_loss += self.mmd(source_feat, target_feat)\n",
    "        \n",
    "        return jmmd_loss / len(source_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cabd30",
   "metadata": {},
   "source": [
    "## GAN define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fb2155c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNormalization(tf.keras.layers.Layer):\n",
    "    def __init__(self, epsilon=1e-5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # gamma and beta for each channel\n",
    "        self.gamma = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=\"ones\",\n",
    "            trainable=True,\n",
    "            name=\"gamma\"\n",
    "        )\n",
    "        self.beta = self.add_weight(\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=\"zeros\",\n",
    "            trainable=True,\n",
    "            name=\"beta\"\n",
    "        )\n",
    "    def call(self, x):\n",
    "        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)\n",
    "        x_norm = (x - mean) / tf.sqrt(variance + self.epsilon)\n",
    "        return self.gamma * x_norm + self.beta\n",
    "    \n",
    "def reflect_padding_2d(x, pad_h, pad_w):\n",
    "    return tf.pad(x, [[0, 0], [pad_h, pad_h], [pad_w, pad_w], [0, 0]], mode='SYMMETRIC')\n",
    "    \n",
    "class UNetBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, apply_dropout=False, kernel_size=(4,3), strides=(2,1), pad_h=0, pad_w=1, gen_l2=None):\n",
    "        super().__init__()\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(gen_l2) if gen_l2 is not None else None\n",
    "        self.pad_h = pad_h\n",
    "        self.pad_w = pad_w\n",
    "        self.conv = tf.keras.layers.Conv2D(filters, kernel_size = kernel_size, strides=strides, padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)\n",
    "        self.norm = InstanceNormalization()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3) if apply_dropout else None\n",
    "\n",
    "    def call(self, x, training):\n",
    "        if self.pad_h > 0 or self.pad_w > 0:\n",
    "            x = reflect_padding_2d(x, pad_h=self.pad_h, pad_w=self.pad_w)  # symmetric padding\n",
    "        x = self.conv(x)\n",
    "        x = self.norm(x, training=training)\n",
    "        x = tf.nn.leaky_relu(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x, training=training)\n",
    "        return x\n",
    "    \n",
    "class UNetUpBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, apply_dropout=False, kernel_size=(4,3), strides=(2,1), gen_l2=None):\n",
    "        super().__init__()\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(gen_l2) if gen_l2 is not None else None\n",
    "        self.deconv = tf.keras.layers.Conv2DTranspose(filters, kernel_size=kernel_size, strides=strides,\n",
    "                                                        padding='valid', kernel_regularizer=kernel_regularizer)\n",
    "        self.norm = InstanceNormalization()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3) if apply_dropout else None\n",
    "\n",
    "    def call(self, x, skip, training):\n",
    "        x = self.deconv(x)\n",
    "        if x.shape[2] >14: \n",
    "            x = x[:, :, 1:15, :]\n",
    "        x = self.norm(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "        if self.dropout:\n",
    "            x = self.dropout(x, training=training)\n",
    "        x = tf.concat([x, skip], axis=-1)\n",
    "        return x\n",
    "\n",
    "class Pix2PixGenerator(tf.keras.Model):\n",
    "    def __init__(self, output_channels=2, n_subc=132, gen_l2=None):\n",
    "        super().__init__()\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(gen_l2) if gen_l2 is not None else None\n",
    "        # Encoder\n",
    "        self.down1 = UNetBlock(32, apply_dropout=False, kernel_size=(4,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.down2 = UNetBlock(64, kernel_size=(3,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.down3 = UNetBlock(128, kernel_size=(4,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.down4 = UNetBlock(256, kernel_size=(3,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        # Decoder\n",
    "        self.up1 = UNetUpBlock(128, apply_dropout=True, kernel_size=(3,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.up2 = UNetUpBlock(64, apply_dropout=True, kernel_size=(4,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.up3 = UNetUpBlock(32, kernel_size=(3,3), strides=(2,1), gen_l2=gen_l2)\n",
    "        self.last = tf.keras.layers.Conv2DTranspose(output_channels, kernel_size=(4,3), strides=(2,1), padding='valid',\n",
    "                                                    activation='tanh', kernel_regularizer=kernel_regularizer)\n",
    "            \n",
    "    def call(self, x, training=False, return_features=False):\n",
    "        # Encoder\n",
    "        d1 = self.down1(x, training=training)      # (batch, 395, 12, C_out)\n",
    "        d2 = self.down2(d1, training=training)     # (batch, 196, 10, C_out)\n",
    "        d3 = self.down3(d2, training=training)     # (batch,  97, 8, C_out)\n",
    "        d4 = self.down4(d3, training=training)     # (batch,  48, 6, C_out)\n",
    "        # Decoder with skip connections\n",
    "        u1 = self.up1(d4, d3, training=training)   # (batch,  97, 8, C_out)\n",
    "        u2 = self.up2(u1, d2, training=training)   # (batch, 196, 10, C_out)\n",
    "        u3 = self.up3(u2, d1, training=training)   # (batch, 395, 12, C_out)\n",
    "        u4 = self.last(u3)  # (batch, 792, 14 or 16, C_out)\n",
    "        \n",
    "        if u4.shape[2] > 14:\n",
    "            u4 = u4[:, :, 1:15, :]\n",
    "        if return_features:\n",
    "            # Return multiple feature layers for JMMD\n",
    "            features = [\n",
    "                tf.reshape(d2, [tf.shape(d2)[0], -1]),  # Feature layer 1\n",
    "                tf.reshape(d3, [tf.shape(d3)[0], -1]),  # Feature layer 2\n",
    "                tf.reshape(d4, [tf.shape(d4)[0], -1])   # Bottleneck layer\n",
    "            ]\n",
    "            return u4, features\n",
    "        return u4, d4\n",
    "\n",
    "class PatchGANDiscriminator(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    PatchGAN Discriminator for Pix2Pix GAN.\n",
    "    Input: (batch, H, W, C)\n",
    "    Output: (batch, H_out, W_out, 1) patch-level real/fake probabilities\n",
    "    \"\"\"\n",
    "    def __init__(self, filters=[32, 64, 128, 256], n_subc=132, disc_l2=None):\n",
    "        super().__init__()\n",
    "        kernel_regularizer = tf.keras.regularizers.l2(disc_l2) if disc_l2 is not None else None\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters[0], kernel_size=(4,3), strides=(2,1), padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters[1], kernel_size=(3,3), strides=(2,1), padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)\n",
    "        self.norm2 = InstanceNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters[2], kernel_size=(4,3), strides=(2,1), padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)\n",
    "        self.norm3 = InstanceNormalization()\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters[3], kernel_size=(3,3), strides=(2,1), padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)\n",
    "        self.norm4 = InstanceNormalization()\n",
    "        self.last = tf.keras.layers.Conv2D(1, kernel_size=(3,3), strides=(2,1), padding='valid',\n",
    "                                            kernel_regularizer=kernel_regularizer)  # Output: patch map\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = tf.nn.leaky_relu(self.conv1(x), alpha=0.2)  # (batch, 395, 12, C_out)\n",
    "        x = tf.nn.leaky_relu(self.norm2(self.conv2(x), training=training), alpha=0.2)  # (batch, 196, 10, C_out)\n",
    "        x = tf.nn.leaky_relu(self.norm3(self.conv3(x), training=training), alpha=0.2)  # (batch, 97, 8, C_out)\n",
    "        x = tf.nn.leaky_relu(self.norm4(self.conv4(x), training=training), alpha=0.2)  # (batch, 48, 6, C_out)\n",
    "        return self.last(x)  # (batch, 23, 3, 1) - patch-level real/fake probabilities\n",
    "\n",
    "class GAN_Output:\n",
    "    \"\"\"Dataclass to hold the output of the GAN model.\"\"\"\n",
    "    def __init__(self, gen_out, disc_out, extracted_features):\n",
    "        self.gen_out = gen_out  # Generator output\n",
    "        self.disc_out = disc_out  # Discriminator output\n",
    "        self.extracted_features = extracted_features  # Extracted features\n",
    "        \n",
    "class GAN(tf.keras.Model):\n",
    "    def __init__(self, n_subc=132, generator=Pix2PixGenerator, discriminator=PatchGANDiscriminator, gen_l2=None, disc_l2=None):\n",
    "        super().__init__()\n",
    "        self.generator = generator(n_subc=n_subc, gen_l2=gen_l2)\n",
    "        self.discriminator = discriminator(n_subc=n_subc, disc_l2=disc_l2)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # Optionally implement a forward pass if needed\n",
    "        x = inputs\n",
    "        gen_out, features = self.generator(x, training=training)\n",
    "        disc_out = self.discriminator(gen_out, training=training)\n",
    "        return GAN_Output(\n",
    "            gen_out=gen_out,\n",
    "            disc_out=disc_out,\n",
    "            extracted_features=features\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5008322",
   "metadata": {},
   "source": [
    "## train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1ca5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(discriminator, real, fake, batch_size):\n",
    "    alpha = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    diff = fake - real\n",
    "    interpolated = real + alpha * diff\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8f5e063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step_wgan_gp_jmmd(model, loader_H, loss_fn, optimizers, lower_range=-1, save_features = False,\n",
    "                            nsymb=14, adv_weight=0.01, est_weight=1.0, jmmd_weight=0.5, linear_interp=False):\n",
    "    \"\"\"\n",
    "    Modified WGAN-GP training step using JMMD instead of domain discriminator\n",
    "    \n",
    "    Args:\n",
    "        model: GAN model instance with generator and discriminator\n",
    "        loader_H: tuple of (loader_H_input_train_src, loader_H_true_train_src, \n",
    "                        loader_H_input_train_tgt, loader_H_true_train_tgt)\n",
    "        loss_fn: tuple of loss functions (estimation_loss, bce_loss) - no domain loss needed\n",
    "        optimizers: tuple of (gen_optimizer, disc_optimizer) - no domain optimizer needed\n",
    "        jmmd_weight: weight for JMMD loss (replaces domain_weight)\n",
    "    \"\"\"\n",
    "    loader_H_input_train_src, loader_H_true_train_src, \\\n",
    "        loader_H_input_train_tgt, loader_H_true_train_tgt = loader_H\n",
    "    loss_fn_est, loss_fn_bce = loss_fn[:2]  # Only need first two loss functions\n",
    "    gen_optimizer, disc_optimizer = optimizers[:2]  # No domain optimizer needed\n",
    "    \n",
    "    # Initialize JMMD loss\n",
    "    jmmd_loss_fn = JMMDLoss()\n",
    "    \n",
    "    epoc_loss_g = 0.0\n",
    "    epoc_loss_d = 0.0\n",
    "    epoc_loss_est = 0.0\n",
    "    epoc_loss_est_tgt = 0.0\n",
    "    epoc_loss_jmmd = 0.0\n",
    "    N_train = 0\n",
    "    \n",
    "    if save_features==True and (jmmd_weight != 0):\n",
    "        features_h5_path_source = 'features_source.h5'\n",
    "        if os.path.exists(features_h5_path_source):\n",
    "            os.remove(features_h5_path_source)  # Remove if exists to start fresh\n",
    "        features_h5_source = h5py.File(features_h5_path_source, 'w')\n",
    "        features_dataset_source = None  # Will be created after first batch\n",
    "\n",
    "        features_h5_path_target = 'features_target.h5'\n",
    "        if os.path.exists(features_h5_path_target):\n",
    "            os.remove(features_h5_path_target)  # Remove if exists to start fresh   \n",
    "        features_h5_target = h5py.File(features_h5_path_target, 'w')\n",
    "        features_dataset_target = None  # Will be created after first batch \n",
    "    \n",
    "    for batch_idx in range(loader_H_true_train_src.total_batches):\n",
    "        # --- Get data ---\n",
    "        x_src = loader_H_input_train_src.next_batch()\n",
    "        y_src = loader_H_true_train_src.next_batch()\n",
    "        x_tgt = loader_H_input_train_tgt.next_batch()\n",
    "        y_tgt = loader_H_true_train_tgt.next_batch()\n",
    "        N_train += x_src.shape[0] + x_tgt.shape[0]\n",
    "\n",
    "        # Preprocess (source)\n",
    "        x_src = complx2real(x_src)\n",
    "        y_src = complx2real(y_src)\n",
    "        x_src = np.transpose(x_src, (0, 2, 3, 1))\n",
    "        y_src = np.transpose(y_src, (0, 2, 3, 1))\n",
    "        x_scaled_src, x_min_src, x_max_src = minmaxScaler(x_src, lower_range=lower_range, linear_interp=linear_interp)\n",
    "        y_scaled_src, _, _ = minmaxScaler(y_src, min_pre=x_min_src, max_pre=x_max_src, lower_range=lower_range)\n",
    "\n",
    "        # Preprocess (target)\n",
    "        x_tgt = complx2real(x_tgt)\n",
    "        y_tgt = complx2real(y_tgt)\n",
    "        x_tgt = np.transpose(x_tgt, (0, 2, 3, 1))\n",
    "        y_tgt = np.transpose(y_tgt, (0, 2, 3, 1))\n",
    "        x_scaled_tgt, x_min_tgt, x_max_tgt = minmaxScaler(x_tgt, lower_range=lower_range, linear_interp=linear_interp)\n",
    "        y_scaled_tgt, _, _ = minmaxScaler(y_tgt, min_pre=x_min_tgt, max_pre=x_max_tgt, lower_range=lower_range)\n",
    "\n",
    "        # === 1. Train Discriminator (WGAN-GP) ===\n",
    "        # Only considering source domain for discriminator training\n",
    "        with tf.GradientTape() as tape_d:\n",
    "            x_fake_src, _ = model.generator(x_scaled_src, training=True, return_features=False)\n",
    "            d_real = model.discriminator(y_scaled_src, training=True)\n",
    "            d_fake = model.discriminator(x_fake_src, training=True)\n",
    "            \n",
    "            # WGAN-GP gradient penalty\n",
    "            gp = gradient_penalty(model.discriminator, y_scaled_src, x_fake_src, batch_size=x_scaled_src.shape[0])\n",
    "            lambda_gp = 10.0  # typical gradient penalty weight\n",
    "\n",
    "            # WGAN-GP discriminator loss\n",
    "            d_loss = tf.reduce_mean(d_fake) - tf.reduce_mean(d_real) + lambda_gp * gp\n",
    "            \n",
    "            # Add L2 regularization loss from discriminator\n",
    "            if model.discriminator.losses:\n",
    "                d_loss += tf.add_n(model.discriminator.losses)\n",
    "                \n",
    "        grads_d = tape_d.gradient(d_loss, model.discriminator.trainable_variables)\n",
    "        disc_optimizer.apply_gradients(zip(grads_d, model.discriminator.trainable_variables))\n",
    "        epoc_loss_d += d_loss.numpy() * x_src.shape[0]\n",
    "\n",
    "        # === 2. Train Generator with JMMD ===\n",
    "        with tf.GradientTape() as tape_g:\n",
    "            # Generate from source domain with features\n",
    "            x_fake_src, features_src = model.generator(x_scaled_src, training=True, return_features=True)\n",
    "            d_fake_src = model.discriminator(x_fake_src, training=False)\n",
    "            \n",
    "            # Generate from target domain with features\n",
    "            x_fake_tgt, features_tgt = model.generator(x_scaled_tgt, training=True, return_features=True)\n",
    "            \n",
    "            # Generator losses\n",
    "            g_adv_loss = -tf.reduce_mean(d_fake_src)  # WGAN-GP adversarial loss\n",
    "            g_est_loss = loss_fn_est(y_scaled_src, x_fake_src)  # Estimation loss (source)\n",
    "            g_est_loss_tgt = loss_fn_est(y_scaled_tgt, x_fake_tgt)  # Estimation loss (target, for monitoring)\n",
    "            \n",
    "            # JMMD loss between source and target features\n",
    "            jmmd_loss = jmmd_loss_fn(features_src, features_tgt)\n",
    "            \n",
    "            # Total generator loss\n",
    "            g_loss = (est_weight * g_est_loss + \n",
    "                     adv_weight * g_adv_loss + \n",
    "                     jmmd_weight * jmmd_loss)\n",
    "            \n",
    "            # Add L2 regularization\n",
    "            if model.generator.losses:\n",
    "                g_loss += tf.add_n(model.generator.losses)\n",
    "        \n",
    "        # === 3. Save features (after the bottleneck layer) if required (to calcu PAD) ===\n",
    "        if save_features and (jmmd_weight != 0):\n",
    "            # save features in a temporary file instead of stacking them up, to avoid memory exploding\n",
    "            features_np_source = features_src[-1].numpy()  # Convert to numpy if it's a tensor\n",
    "            # print('Feature shape: ', features_np_source.shape)\n",
    "            if features_dataset_source is None:\n",
    "                # Create dataset with unlimited first dimension\n",
    "                features_dataset_source = features_h5_source.create_dataset(\n",
    "                    'features',\n",
    "                    data=features_np_source,\n",
    "                    maxshape=(None,) + features_np_source.shape[1:],\n",
    "                    chunks=True\n",
    "                )\n",
    "            else:\n",
    "                # Resize and append\n",
    "                features_dataset_source.resize(features_dataset_source.shape[0] + features_np_source.shape[0], axis=0)\n",
    "                features_dataset_source[-features_np_source.shape[0]:] = features_np_source\n",
    "                \n",
    "            features_np_target = features_tgt[-1].numpy()\n",
    "            if features_dataset_target is None:\n",
    "                # Create dataset with unlimited first dimension\n",
    "                features_dataset_target = features_h5_target.create_dataset(\n",
    "                    'features',\n",
    "                    data=features_np_target,\n",
    "                    maxshape=(None,) + features_np_target.shape[1:],\n",
    "                    chunks=True\n",
    "                )\n",
    "            else:\n",
    "                # Resize and append\n",
    "                features_dataset_target.resize(features_dataset_target.shape[0] + features_np_target.shape[0], axis=0)\n",
    "                features_dataset_target[-features_np_target.shape[0]:] = features_np_target\n",
    "                \n",
    "        grads_g = tape_g.gradient(g_loss, model.generator.trainable_variables)\n",
    "        gen_optimizer.apply_gradients(zip(grads_g, model.generator.trainable_variables))\n",
    "        \n",
    "        epoc_loss_g += g_loss.numpy() * x_src.shape[0]\n",
    "        epoc_loss_est += g_est_loss.numpy() * x_src.shape[0]\n",
    "        epoc_loss_est_tgt += g_est_loss_tgt.numpy() * x_tgt.shape[0]\n",
    "        epoc_loss_jmmd += jmmd_loss.numpy() * x_src.shape[0]\n",
    "    # end batch loop\n",
    "    if save_features and (jmmd_weight != 0):    \n",
    "        features_h5_source.close()\n",
    "        features_h5_target.close()\n",
    "    \n",
    "    # Average losses\n",
    "    avg_loss_g = epoc_loss_g / N_train\n",
    "    avg_loss_d = epoc_loss_d / N_train\n",
    "    avg_loss_est = epoc_loss_est / N_train\n",
    "    avg_loss_jmmd = epoc_loss_jmmd / N_train\n",
    "    avg_loss_est_tgt = epoc_loss_est_tgt / N_train\n",
    "    \n",
    "    # Return compatible output structure (replacing domain loss with JMMD)\n",
    "    return train_step_Output(\n",
    "        avg_epoc_loss_est=avg_loss_est,\n",
    "        avg_epoc_loss_domain=avg_loss_jmmd,  # Replace domain loss with JMMD\n",
    "        avg_epoc_loss=avg_loss_g,\n",
    "        avg_epoc_loss_est_target=avg_loss_est_tgt,\n",
    "        features_source=features_src[-1] if features_src else None,  # Return bottleneck features\n",
    "        film_features_source=features_src[-1] if features_src else None,\n",
    "        avg_epoc_loss_d=avg_loss_d\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afa849b",
   "metadata": {},
   "source": [
    "## val step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72cd333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_step_wgan_gp_jmmd(model, loader_H, loss_fn, lower_range, nsymb=14, adv_weight=0.01, est_weight=1.0, jmmd_weight=0.5, linear_interp=False):\n",
    "    \"\"\"\n",
    "    Validation step for WGAN-GP model with JMMD. Returns H_sample and epoc_eval_return (summary metrics).\n",
    "    \n",
    "    Args:\n",
    "        model: GAN model instance with generator and discriminator\n",
    "        loader_H: tuple of (input_src, true_src, input_tgt, true_tgt) DataLoaders\n",
    "        loss_fn: tuple of (estimation loss, binary cross-entropy loss) - no domain loss needed\n",
    "        lower_range: lower range for min-max scaling\n",
    "        nsymb: number of symbols\n",
    "        adv_weight, est_weight, jmmd_weight: loss weights\n",
    "        \n",
    "    Returns:\n",
    "        H_sample, epoc_eval_return\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    \n",
    "    loader_H_input_val_source, loader_H_true_val_source, loader_H_input_val_target, loader_H_true_val_target = loader_H\n",
    "    loss_fn_est, loss_fn_bce = loss_fn[:2]  # Only need first two loss functions\n",
    "    \n",
    "    # Initialize JMMD loss\n",
    "    jmmd_loss_fn = JMMDLoss()\n",
    "    \n",
    "    N_val_source = 0\n",
    "    N_val_target = 0\n",
    "    epoc_loss_est_source = 0.0\n",
    "    epoc_loss_est_target = 0.0\n",
    "    epoc_nmse_val_source = 0.0\n",
    "    epoc_nmse_val_target = 0.0\n",
    "    epoc_gan_disc_loss = 0.0\n",
    "    epoc_jmmd_loss = 0.0  # Replace domain loss with JMMD\n",
    "    H_sample = []\n",
    "\n",
    "    for idx in range(loader_H_true_val_source.total_batches):\n",
    "        # --- Source domain ---\n",
    "        x_src = loader_H_input_val_source.next_batch()\n",
    "        y_src = loader_H_true_val_source.next_batch()\n",
    "        # --- Target domain ---\n",
    "        x_tgt = loader_H_input_val_target.next_batch()\n",
    "        y_tgt = loader_H_true_val_target.next_batch()\n",
    "        N_val_source += x_src.shape[0]\n",
    "        N_val_target += x_tgt.shape[0]\n",
    "\n",
    "        # Preprocess (source)\n",
    "        x_src_real = complx2real(x_src)\n",
    "        y_src_real = complx2real(y_src)\n",
    "        x_src_real = np.transpose(x_src_real, (0, 2, 3, 1))\n",
    "        y_src_real = np.transpose(y_src_real, (0, 2, 3, 1))\n",
    "        x_scaled_src, x_min_src, x_max_src = minmaxScaler(x_src_real, lower_range=lower_range, linear_interp=linear_interp)\n",
    "        y_scaled_src, _, _ = minmaxScaler(y_src_real, min_pre=x_min_src, max_pre=x_max_src, lower_range=lower_range)\n",
    "\n",
    "        # Preprocess (target)\n",
    "        x_tgt_real = complx2real(x_tgt)\n",
    "        y_tgt_real = complx2real(y_tgt)\n",
    "        x_tgt_real = np.transpose(x_tgt_real, (0, 2, 3, 1))\n",
    "        y_tgt_real = np.transpose(y_tgt_real, (0, 2, 3, 1))\n",
    "        x_scaled_tgt, x_min_tgt, x_max_tgt = minmaxScaler(x_tgt_real, lower_range=lower_range, linear_interp=linear_interp)\n",
    "        y_scaled_tgt, _, _ = minmaxScaler(y_tgt_real, min_pre=x_min_tgt, max_pre=x_max_tgt, lower_range=lower_range)\n",
    "\n",
    "        # === Source domain prediction ===\n",
    "        preds_src, features_src = model.generator(x_scaled_src, training=False, return_features=True)\n",
    "        preds_src = preds_src.numpy() if hasattr(preds_src, 'numpy') else preds_src\n",
    "        preds_src_descaled = deMinMax(preds_src, x_min_src, x_max_src, lower_range=lower_range)\n",
    "        batch_est_loss_source = loss_fn_est(y_scaled_src, preds_src).numpy()\n",
    "        epoc_loss_est_source += batch_est_loss_source * x_src.shape[0]\n",
    "        mse_val_source = np.mean((preds_src_descaled - y_src_real) ** 2, axis=(1, 2, 3))\n",
    "        power_source = np.mean(y_src_real ** 2, axis=(1, 2, 3))\n",
    "        epoc_nmse_val_source += np.mean(mse_val_source / (power_source + 1e-30)) * x_src.shape[0]\n",
    "\n",
    "        # === Target domain prediction ===\n",
    "        preds_tgt, features_tgt = model.generator(x_scaled_tgt, training=False, return_features=True)\n",
    "        preds_tgt = preds_tgt.numpy() if hasattr(preds_tgt, 'numpy') else preds_tgt\n",
    "        preds_tgt_descaled = deMinMax(preds_tgt, x_min_tgt, x_max_tgt, lower_range=lower_range)\n",
    "        batch_est_loss_target = loss_fn_est(y_scaled_tgt, preds_tgt).numpy()\n",
    "        epoc_loss_est_target += batch_est_loss_target * x_tgt.shape[0]\n",
    "        mse_val_target = np.mean((preds_tgt_descaled - y_tgt_real) ** 2, axis=(1, 2, 3))\n",
    "        power_target = np.mean(y_tgt_real ** 2, axis=(1, 2, 3))\n",
    "        epoc_nmse_val_target += np.mean(mse_val_target / (power_target + 1e-30)) * x_tgt.shape[0]\n",
    "\n",
    "        # === WGAN Discriminator Scores (for monitoring only) ===\n",
    "        # Only considering source domain\n",
    "        d_real_src = model.discriminator(y_scaled_src, training=False)\n",
    "        d_fake_src = model.discriminator(preds_src, training=False)\n",
    "        gp_src = gradient_penalty(model.discriminator, y_scaled_src, preds_src, batch_size=x_scaled_src.shape[0])\n",
    "        lambda_gp = 10.0  # typical gradient penalty weight\n",
    "        \n",
    "        # WGAN critic loss: mean(fake) - mean(real)\n",
    "        d_loss_src = tf.reduce_mean(d_fake_src) - tf.reduce_mean(d_real_src) + lambda_gp * gp_src\n",
    "        \n",
    "        # only observe GAN disc loss on source dataset\n",
    "        epoc_gan_disc_loss += d_loss_src.numpy() * x_src.shape[0]\n",
    "\n",
    "        # === JMMD Loss (replaces Domain Discriminator) ===\n",
    "        if jmmd_weight > 0:\n",
    "            # Compute JMMD loss between source and target features\n",
    "            jmmd_loss = jmmd_loss_fn(features_src, features_tgt)\n",
    "            epoc_jmmd_loss += jmmd_loss.numpy() * x_src.shape[0]\n",
    "\n",
    "        # === Save H samples for visualization at first batch ===\n",
    "        if idx == 0:\n",
    "            n_samples = min(3, x_src_real.shape[0], x_tgt_real.shape[0])\n",
    "            # Source\n",
    "            H_true_sample = y_src_real[:n_samples].copy()\n",
    "            H_input_sample = x_src_real[:n_samples].copy()\n",
    "            #\n",
    "            if hasattr(preds_src_descaled, 'numpy'):\n",
    "                H_est_sample = preds_src_descaled[:n_samples].numpy().copy()\n",
    "            else:\n",
    "                H_est_sample = preds_src_descaled[:n_samples].copy()\n",
    "            #\n",
    "            mse_sample_source = np.mean((H_est_sample - H_true_sample) ** 2, axis=(1, 2, 3))\n",
    "            power_sample_source = np.mean(H_true_sample ** 2, axis=(1, 2, 3))\n",
    "            nmse_est_source = mse_sample_source / (power_sample_source + 1e-30)\n",
    "            mse_input_source = np.mean((H_input_sample - H_true_sample) ** 2, axis=(1, 2, 3))\n",
    "            nmse_input_source = mse_input_source / (power_sample_source + 1e-30)\n",
    "            # Target\n",
    "            H_true_sample_target = y_tgt_real[:n_samples].copy()\n",
    "            H_input_sample_target = x_tgt_real[:n_samples].copy()\n",
    "            #\n",
    "            if hasattr(preds_tgt_descaled, 'numpy'):\n",
    "                H_est_sample_target = preds_tgt_descaled[:n_samples].numpy().copy()\n",
    "            else:\n",
    "                H_est_sample_target = preds_tgt_descaled[:n_samples].copy()\n",
    "            #\n",
    "            mse_sample_target = np.mean((H_est_sample_target - H_true_sample_target) ** 2, axis=(1, 2, 3))\n",
    "            power_sample_target = np.mean(H_true_sample_target ** 2, axis=(1, 2, 3))\n",
    "            nmse_est_target = mse_sample_target / (power_sample_target + 1e-30)\n",
    "            mse_input_target = np.mean((H_input_sample_target - H_true_sample_target) ** 2, axis=(1, 2, 3))\n",
    "            nmse_input_target = mse_input_target / (power_sample_target + 1e-30)\n",
    "            H_sample = [H_true_sample, H_input_sample, H_est_sample, nmse_input_source, nmse_est_source,\n",
    "                        H_true_sample_target, H_input_sample_target, H_est_sample_target, nmse_input_target, nmse_est_target]\n",
    "\n",
    "    # Calculate averages\n",
    "    N_val = N_val_source + N_val_target\n",
    "    avg_loss_est_source = epoc_loss_est_source / N_val_source\n",
    "    avg_loss_est_target = epoc_loss_est_target / N_val_target\n",
    "    avg_loss_est = (avg_loss_est_source + avg_loss_est_target) / 2\n",
    "    avg_nmse_source = epoc_nmse_val_source / N_val_source\n",
    "    avg_nmse_target = epoc_nmse_val_target / N_val_target\n",
    "    avg_nmse = (avg_nmse_source + avg_nmse_target) / 2\n",
    "    # only observe GAN disc loss on source dataset\n",
    "    avg_gan_disc_loss = epoc_gan_disc_loss / N_val_source \n",
    "    \n",
    "    # JMMD loss average (replaces domain discriminator loss)\n",
    "    avg_jmmd_loss = epoc_jmmd_loss / N_val_source if epoc_jmmd_loss > 0 else 0.0\n",
    "    \n",
    "    # For compatibility with existing code, we'll set domain accuracy to 0.5 (random)\n",
    "    # since JMMD doesn't have classification accuracy\n",
    "    avg_domain_acc_source = 0.5  # Neutral value for JMMD (no classification)\n",
    "    avg_domain_acc_target = 0.5  # Neutral value for JMMD (no classification)\n",
    "    avg_domain_acc = 0.5         # Neutral value for JMMD (no classification)\n",
    "\n",
    "    # Weighted total loss (for comparison with training)\n",
    "    avg_total_loss = est_weight * avg_loss_est + adv_weight * avg_gan_disc_loss + jmmd_weight * avg_jmmd_loss\n",
    "\n",
    "    # Compose epoc_eval_return - Replace domain discriminator loss with JMMD loss\n",
    "    epoc_eval_return = [\n",
    "        avg_total_loss,\n",
    "        avg_loss_est_source, avg_loss_est_target, avg_loss_est,\n",
    "        avg_gan_disc_loss, avg_jmmd_loss,  # Replace domain_disc_loss with jmmd_loss\n",
    "        avg_nmse_source, avg_nmse_target, avg_nmse,\n",
    "        avg_domain_acc_source, avg_domain_acc_target, avg_domain_acc  # Keep for compatibility\n",
    "    ]\n",
    "\n",
    "    return H_sample, epoc_eval_return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc88a94",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f90e823",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR = 0\n",
    "# source_data_file_path_label = os.path.abspath(os.path.join(notebook_dir, '..', 'generatedChan', 'OpenNTN','H_perfect.mat'))\n",
    "source_data_file_path = os.path.abspath(os.path.join(notebook_dir, '..', 'generatedChan', 'MATLAB', 'tdlA_tdlC', 'tdlA', 'matlabNTN.mat'))\n",
    "target_data_file_path = os.path.abspath(os.path.join(notebook_dir, '..', 'generatedChan', 'MATLAB', 'tdlA_tdlC', 'tdlC', 'matlabNTN.mat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6803a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "lower_range = -1 \n",
    "    # if norm_approach = 'minmax': \n",
    "        # =  0 for scaling to  [0 1]\n",
    "        # = -1 for scaling to [-1 1]\n",
    "    # if norm_approach = 'std': can be any value, but need to be defined\n",
    "adv_weight=0.005\n",
    "est_weight=1\n",
    "domain_weight=0.5  # for Domain Discriminator, 0 for no Domain Discriminator\n",
    "\n",
    "# snr_start = -25\n",
    "# snr_step = 5\n",
    "# snr_end = 25\n",
    "# SNR = np.arange(snr_start, snr_end+1, snr_step)\n",
    "\n",
    "# SNR = np.array([0])\n",
    "\n",
    "# if len(SNR) >1:\n",
    "#     SNR_txt = f'{snr_start}:{snr_step}:{snr_end}'\n",
    "# else:\n",
    "#     SNR_txt = f'{SNR[0]}'\n",
    "    \n",
    "# ============ CNN settings ==============\n",
    "if norm_approach == 'minmax':\n",
    "    if lower_range == 0:\n",
    "        norm_txt = 'Using min-max [0 1]'\n",
    "    elif lower_range ==-1:\n",
    "        norm_txt = 'Using min-max [-1 1]'\n",
    "elif norm_approach == 'no':\n",
    "    norm_txt = 'No'\n",
    "    \n",
    "CNN_activation = 'Tanh'\n",
    "CNN_DropOut = 0.2\n",
    "if CNN_DropOut != 0:\n",
    "    dropOut_txt = f'Add p={CNN_DropOut} DropOut'\n",
    "    \n",
    "# ============ Adversarial for Domain Discriminator settings ==============\n",
    "    \n",
    "    \n",
    "# # create readme.txt file\n",
    "# content = f\"\"\"Generated by file 'Domain_Adversarial/UDA_CNN_v3.ipynb'.\n",
    "# 28 GHz fc,\n",
    "# Source dataset got from {source_data_file_path},\n",
    "# Target dataset got from {target_data_file_path},\n",
    "# Learning rate {learning_rate},\n",
    "# {norm_txt} scaler for each sample\n",
    "# Using {CNN_activation} as activation function of CNN\n",
    "# {dropOut_txt}\n",
    "# ========= For Domain Discriminator ==========\n",
    "# Extract features after layer {extract_layer} of CNN\n",
    "# {text_lambda}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73be6772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename(notebook_dir + '/model/GAN','ver', '_', '')\n",
    "\n",
    "save_model = 0\n",
    "model_path = notebook_dir + '/model/GAN/ver' + str(idx_save_path) + '_'\n",
    "# figure_path = notebook_dir + '/model/GAN/ver' + str(idx_save_path) + '_/figure'\n",
    "model_readme = model_path + '/readme.txt'\n",
    "# figure_readme = figure_path + '/readme.txt'\n",
    "\n",
    "# if not os.path.exists(os.path.dirname(model_readme)):\n",
    "#     os.makedirs(os.path.dirname(model_readme))\n",
    "# # if not os.path.exists(os.path.dirname(figure_readme)):\n",
    "# #     os.makedirs(os.path.dirname(figure_readme))\n",
    "\n",
    "# # Open the file in write mode ('w'). If the file does not exist, it will be created.\n",
    "# with open(model_readme, 'w') as file:\n",
    "#     # Write the content to the file\n",
    "#     file.write(content)\n",
    "\n",
    "# # with open(figure_readme, 'w') as file:\n",
    "# #     # Write the content to the file\n",
    "# #     file.write(content)\n",
    "\n",
    "# print(f\"File '{model_readme}'  created and content written.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0fbd42",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bc85339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_samp_source =  2048\n",
      "N_samp_target =  2048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "# ============ Source data ==============\n",
    "source_file = h5py.File(source_data_file_path, 'r')\n",
    "H_true_source = source_file['H_perfect']\n",
    "N_samp_source = H_true_source.shape[0]\n",
    "print('N_samp_source = ', N_samp_source)\n",
    "\n",
    "# ============ Target data ==============\n",
    "target_file = h5py.File(target_data_file_path, 'r')\n",
    "H_true_target = target_file['H_perfect']\n",
    "N_samp_target = H_true_target.shape[0]\n",
    "print('N_samp_target = ', N_samp_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4247fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size =  96\n",
      "val_size =  16\n"
     ]
    }
   ],
   "source": [
    "# Store random state \n",
    "rng_state = np.random.get_state()\n",
    "\n",
    "# --- Set a temporary seed for reproducible split ---\n",
    "np.random.seed(1234)   # any fixed integer seed\n",
    "# Random but repeatable split\n",
    "indices_source = np.arange(N_samp_source)\n",
    "np.random.shuffle(indices_source)\n",
    "indices_target = np.arange(N_samp_target)\n",
    "np.random.shuffle(indices_target)\n",
    "# Restore previous random state (so other code stays random)\n",
    "np.random.set_state(rng_state)\n",
    "#\n",
    "train_size = int(np.floor(N_samp_source * 0.9) // batch_size * batch_size)\n",
    "val_size = N_samp_source - train_size\n",
    "\n",
    "# Repeat the indices to match the maximum number of samples\n",
    "N_samp = max(N_samp_source, N_samp_target) \n",
    "indices_source = np.resize(indices_source, N_samp)\n",
    "indices_target = np.resize(indices_target, N_samp)\n",
    "\n",
    "# =======================================================\n",
    "## Divide the indices into training and validation sets\n",
    "# indices_train_source = indices_source[:train_size]\n",
    "# indices_val_source   = indices_source[train_size:train_size + val_size]\n",
    "\n",
    "# indices_train_target = indices_target[:train_size]\n",
    "# indices_val_target   = indices_target[train_size:train_size + val_size]\n",
    "\n",
    "# to test code\n",
    "indices_train_source = indices_source[:96]\n",
    "indices_val_source = indices_source[2032:]\n",
    "indices_train_target = indices_target[:96]\n",
    "indices_val_target = indices_target[2032:]\n",
    "\n",
    "print('train_size = ', indices_train_source.shape[0])\n",
    "print('val_size = ', indices_val_source.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65452f39",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bdf7c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaders:\n",
    "    def __init__(self, file, indices_train, indices_val, tag='prac', batch_size=32): \n",
    "        # tag = 'prac' or 'li' or 'ls'\n",
    "        self.true_train = H5BatchLoader(file, dataset_name='H_perfect', batch_size=batch_size, shuffled_indices=indices_train)\n",
    "        self.true_val = H5BatchLoader(file, dataset_name='H_perfect', batch_size=batch_size, shuffled_indices=indices_val)\n",
    "\n",
    "        self.input_train = H5BatchLoader(file, f'H_{tag}', batch_size=batch_size, shuffled_indices=indices_train)\n",
    "        self.input_val = H5BatchLoader(file, f'H_{tag}', batch_size=batch_size, shuffled_indices=indices_val)\n",
    "\n",
    "# Source domain\n",
    "class_dict_source = {\n",
    "    'GAN_practical': DataLoaders(source_file, indices_train_source, indices_val_source, tag='prac', batch_size=batch_size),\n",
    "    'GAN_linear': DataLoaders(source_file, indices_train_source, indices_val_source, tag='li', batch_size=batch_size),\n",
    "    'GAN_ls': DataLoaders(source_file, indices_train_source, indices_val_source, tag='ls', batch_size=batch_size)\n",
    "}\n",
    "\n",
    "# Target domain\n",
    "class_dict_target = {\n",
    "    'GAN_practical': DataLoaders(target_file, indices_train_target, indices_val_target, tag='prac', batch_size=batch_size),\n",
    "    'GAN_linear': DataLoaders(target_file, indices_train_target, indices_val_target, tag='li', batch_size=batch_size),\n",
    "    'GAN_ls': DataLoaders(target_file, indices_train_target, indices_val_target, tag='ls', batch_size=batch_size)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "363fec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_ce = tf.keras.losses.MeanSquaredError()  # Channel estimation loss (generator loss)\n",
    "loss_fn_bce = tf.keras.losses.BinaryCrossentropy(from_logits=False) # Binary cross-entropy loss for discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53176091",
   "metadata": {},
   "source": [
    "# Running Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d67064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: GAN_practical\n",
      "Calculating Wasserstein-1 distance for original input training datasets (before training)...\n",
      "Calculating Wasserstein-1 distance for original input training datasets (before training)...\n",
      "X shape =  (192, 528)\n",
      "X1 shape =  (96, 528) y1 shape =  (96,)\n",
      "(96, 528) (96,)\n",
      "C: 0.01, Error rate: 0.5208\n",
      "C: 0.1, Error rate: 0.3021\n",
      "C: 0.5, Error rate: 0.1458\n",
      "C: 1.0, Error rate: 0.0833\n",
      "C: 2.0, Error rate: 0.0104\n",
      "C: 5.0, Error rate: 0.0104\n",
      "C: 10.0, Error rate: 0.0000\n",
      "C: 50.0, Error rate: 0.0000\n",
      "C: 100.0, Error rate: 0.0000\n",
      "C: 500.0, Error rate: 0.0000\n",
      "C: 1000.0, Error rate: 0.0000\n",
      "Best C: 10.0, Best error rate: 0.0000\n",
      "PAD = 2.0000\n",
      "PAD = 2.0000\n",
      "X shape =  (192, 528)\n",
      "X1 shape =  (96, 528) y1 shape =  (96,)\n",
      "(96, 528) (96,)\n",
      "C: 0.01, Error rate: 0.5208\n",
      "C: 0.1, Error rate: 0.3021\n",
      "C: 0.5, Error rate: 0.1458\n",
      "C: 1.0, Error rate: 0.0833\n",
      "C: 2.0, Error rate: 0.0104\n",
      "C: 5.0, Error rate: 0.0104\n",
      "C: 10.0, Error rate: 0.0000\n",
      "C: 50.0, Error rate: 0.0000\n",
      "C: 100.0, Error rate: 0.0000\n",
      "C: 500.0, Error rate: 0.0000\n",
      "C: 1000.0, Error rate: 0.0000\n",
      "Best C: 10.0, Best error rate: 0.0000\n",
      "PAD = 2.0000\n",
      "PAD = 2.0000\n",
      "Fitted PCA on batch: source 96/96, target 96/96\n",
      "Reduced source shape: (96, 100), target shape: (96, 100)\n",
      "== C: 0.01, Error rate: 0.5208\n",
      "== C: 0.1, Error rate: 0.4271\n",
      "== C: 0.5, Error rate: 0.1875\n",
      "== C: 1.0, Error rate: 0.1354\n",
      "== C: 2.0, Error rate: 0.0312\n",
      "== C: 5.0, Error rate: 0.0104\n",
      "== C: 10.0, Error rate: 0.0000\n",
      "== C: 50.0, Error rate: 0.0000\n",
      "== C: 100.0, Error rate: 0.0000\n",
      "== C: 500.0, Error rate: 0.0000\n",
      "== C: 1000.0, Error rate: 0.0000\n",
      "Best C: 10.0, Best error rate: 0.0000\n",
      "============ PAD (SVM) = 2.0000\n",
      "LDA Error rate: 0.3229\n",
      "============ PAD (LDA) = 0.7083\n",
      "Logistic Regression Error rate: 0.5208\n",
      "Flip the predictions\n",
      "============ PAD (LogReg) = 0.0833\n",
      "Fitted PCA on batch: source 96/96, target 96/96\n",
      "Reduced source shape: (96, 100), target shape: (96, 100)\n",
      "== C: 0.01, Error rate: 0.5208\n",
      "== C: 0.1, Error rate: 0.4271\n",
      "== C: 0.5, Error rate: 0.1875\n",
      "== C: 1.0, Error rate: 0.1354\n",
      "== C: 2.0, Error rate: 0.0312\n",
      "== C: 5.0, Error rate: 0.0104\n",
      "== C: 10.0, Error rate: 0.0000\n",
      "== C: 50.0, Error rate: 0.0000\n",
      "== C: 100.0, Error rate: 0.0000\n",
      "== C: 500.0, Error rate: 0.0000\n",
      "== C: 1000.0, Error rate: 0.0000\n",
      "Best C: 10.0, Best error rate: 0.0000\n",
      "============ PAD (SVM) = 2.0000\n",
      "LDA Error rate: 0.3229\n",
      "============ PAD (LDA) = 0.7083\n",
      "Logistic Regression Error rate: 0.5208\n",
      "Flip the predictions\n",
      "============ PAD (LogReg) = 0.0833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761147765.408560    4792 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9553 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:1a:00.0, compute capability: 7.5\n",
      "I0000 00:00:1761147765.409089    4792 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 9548 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:67:00.0, compute capability: 7.5\n",
      "I0000 00:00:1761147765.409553    4792 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 9486 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:68:00.0, compute capability: 7.5\n",
      "I0000 00:00:1761147768.196106    4792 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1761147768.196106    4792 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time 18.192934204000267 seconds\n",
      "epoch 1/5\n",
      "Fitting IncrementalPCA on batches from features_source.h5 and features_target.h5\n",
      "Fitted PCA on batch: source 96/96, target 96/96\n",
      "Reduced source shape: (96, 100), target shape: (96, 100)\n",
      "== C: 0.01, Error rate: 0.5208\n",
      "== C: 0.1, Error rate: 0.0000\n",
      "== C: 0.5, Error rate: 0.0000\n",
      "== C: 1.0, Error rate: 0.0000\n",
      "== C: 2.0, Error rate: 0.0000\n",
      "== C: 5.0, Error rate: 0.0000\n",
      "== C: 10.0, Error rate: 0.0000\n",
      "== C: 50.0, Error rate: 0.0000\n",
      "== C: 100.0, Error rate: 0.0000\n",
      "== C: 500.0, Error rate: 0.0000\n",
      "== C: 1000.0, Error rate: 0.0000\n",
      "Best C: 0.1, Best error rate: 0.0000\n",
      "============ PAD (SVM) = 2.0000\n",
      "LDA Error rate: 0.0938\n",
      "============ PAD (LDA) = 1.6250\n",
      "Logistic Regression Error rate: 0.0000\n",
      "============ PAD (LogReg) = 2.0000\n",
      "Fitted PCA on batch: source 96/96, target 96/96\n",
      "Reduced source shape: (96, 100), target shape: (96, 100)\n",
      "== C: 0.01, Error rate: 0.5208\n",
      "== C: 0.1, Error rate: 0.0000\n",
      "== C: 0.5, Error rate: 0.0000\n",
      "== C: 1.0, Error rate: 0.0000\n",
      "== C: 2.0, Error rate: 0.0000\n",
      "== C: 5.0, Error rate: 0.0000\n",
      "== C: 10.0, Error rate: 0.0000\n",
      "== C: 50.0, Error rate: 0.0000\n",
      "== C: 100.0, Error rate: 0.0000\n",
      "== C: 500.0, Error rate: 0.0000\n",
      "== C: 1000.0, Error rate: 0.0000\n",
      "Best C: 0.1, Best error rate: 0.0000\n",
      "============ PAD (SVM) = 2.0000\n",
      "LDA Error rate: 0.0938\n",
      "============ PAD (LDA) = 1.6250\n",
      "Logistic Regression Error rate: 0.0000\n",
      "============ PAD (LogReg) = 2.0000\n",
      "Time 20.526014013999884 seconds\n",
      "epoch 1/5 Average Training Loss: 2.526522\n",
      "epoch 1/5 Average Estimation Loss (in Source domain): 1.748843\n",
      "epoch 1/5 Average Disc Loss (in Source domain): 1855.079102\n",
      "epoch 1/5 Average JMMD Loss: 1.556020\n",
      "epoch 1/5 For observation only - Average Estimation Loss in Target domain: 3.028268\n",
      "Time 20.526014013999884 seconds\n",
      "epoch 1/5 Average Training Loss: 2.526522\n",
      "epoch 1/5 Average Estimation Loss (in Source domain): 1.748843\n",
      "epoch 1/5 Average Disc Loss (in Source domain): 1855.079102\n",
      "epoch 1/5 Average JMMD Loss: 1.556020\n",
      "epoch 1/5 For observation only - Average Estimation Loss in Target domain: 3.028268\n",
      "epoch 1/5 (Val) Weighted Total Loss: 21.368399\n",
      "epoch 1/5 (Val) Average Estimation Loss (mean): 4.971758\n",
      "epoch 1/5 (Val) Average Estimation Loss (Source): 4.271922\n",
      "epoch 1/5 (Val) Average Estimation Loss (Target): 5.671595\n",
      "epoch 1/5 (Val) GAN Discriminator Loss: 2978.050049\n",
      "epoch 1/5 (Val) Domain Discriminator Loss: 3.012780\n",
      "epoch 1/5 (Val) NMSE (Source): 1.502992, NMSE (Target): 1.522498, NMSE (Mean): 1.512745\n",
      "epoch 1/5 (Val) Domain Discriminator Accuracy (Average): 0.5000\n",
      "epoch 1/5 (Val) Weighted Total Loss: 21.368399\n",
      "epoch 1/5 (Val) Average Estimation Loss (mean): 4.971758\n",
      "epoch 1/5 (Val) Average Estimation Loss (Source): 4.271922\n",
      "epoch 1/5 (Val) Average Estimation Loss (Target): 5.671595\n",
      "epoch 1/5 (Val) GAN Discriminator Loss: 2978.050049\n",
      "epoch 1/5 (Val) Domain Discriminator Loss: 3.012780\n",
      "epoch 1/5 (Val) NMSE (Source): 1.502992, NMSE (Target): 1.522498, NMSE (Mean): 1.512745\n",
      "epoch 1/5 (Val) Domain Discriminator Accuracy (Average): 0.5000\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'all'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 217\u001b[39m\n\u001b[32m    212\u001b[39m     post_val(epoc_val_return, epoch, n_epochs, val_est_loss, val_est_loss_source, val_loss, val_est_loss_target,\n\u001b[32m    213\u001b[39m         val_gan_disc_loss, val_domain_disc_loss, nmse_val_source, nmse_val_target, nmse_val, source_acc, target_acc, acc, domain_weight=domain_weight)\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (epoch==epoch_min) \u001b[38;5;129;01mor\u001b[39;00m (epoch+\u001b[32m1\u001b[39m>epoch_min \u001b[38;5;129;01mand\u001b[39;00m (epoch-epoch_min)%epoch_step==\u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m epoch==n_epochs-\u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m         \u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplotfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfigLoss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msavemat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_est_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_domain_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_est_loss_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m                \u001b[49m\u001b[43mval_est_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_est_loss_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_est_loss_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gan_disc_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_domain_disc_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m                \u001b[49m\u001b[43msource_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_acc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43macc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmse_val_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmse_val_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnmse_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_pca_svm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_pca_lda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_pca_logreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoc_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_svm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_disc_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdomain_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[38;5;66;03m# end of epoch loop\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# =====================            \u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;66;03m# Save performances\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# Save H matrix\u001b[39;00m\n\u001b[32m    225\u001b[39m savemat(model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/H_visualize/H_trix.mat\u001b[39m\u001b[33m'\u001b[39m, H_to_save)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/NTN/Hest_NTN_UDA/Domain_Adversarial/helper/utils_GAN.py:1113\u001b[39m, in \u001b[36msave_checkpoint\u001b[39m\u001b[34m(model, save_model, model_path, sub_folder, epoch, figLoss, savemat, train_loss, train_est_loss, train_domain_loss, train_est_loss_target, val_est_loss, val_est_loss_source, val_loss, val_est_loss_target, val_gan_disc_loss, val_domain_disc_loss, source_acc, target_acc, acc, nmse_val_source, nmse_val_target, nmse_val, pad_pca_svm, pad_pca_lda, pad_pca_logreg, epoc_pad, pad_svm, train_disc_loss, domain_weight, optimizer, domain_model)\u001b[39m\n\u001b[32m   1111\u001b[39m \u001b[38;5;66;03m# Plot figures === save and overwrite at checkpoints\u001b[39;00m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m domain_weight:\n\u001b[32m-> \u001b[39m\u001b[32m1113\u001b[39m     \u001b[43mfigLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnmse_val_source\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mSource Domain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnmse_val_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTarget Domain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEpoch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mylabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNMSE\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1114\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNMSE in Validation\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_save\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_save_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/performance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mNMSE_val\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1115\u001b[39m     figLoss(line_list=[(source_acc, \u001b[33m'\u001b[39m\u001b[33mSource Domain\u001b[39m\u001b[33m'\u001b[39m), (target_acc, \u001b[33m'\u001b[39m\u001b[33mTarget Domain\u001b[39m\u001b[33m'\u001b[39m)], xlabel=\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m, ylabel=\u001b[33m'\u001b[39m\u001b[33mDiscrimination Accuracy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1116\u001b[39m                 title=\u001b[33m'\u001b[39m\u001b[33mDomain Discrimination Accuracy in Validation\u001b[39m\u001b[33m'\u001b[39m, index_save=\u001b[32m1\u001b[39m, figure_save_path= model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/performance\u001b[39m\u001b[33m'\u001b[39m, fig_name=\u001b[33m'\u001b[39m\u001b[33mDomain_acc\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1117\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/NTN/Hest_NTN_UDA/Domain_Adversarial/helper/plotfig.py:17\u001b[39m, in \u001b[36mfigLoss\u001b[39m\u001b[34m(line_list, index_save, figure_save_path, fig_show, fig_name, xlabel, ylabel, title, x)\u001b[39m\n\u001b[32m     15\u001b[39m plt.figure(figsize=(\u001b[32m10\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m     16\u001b[39m line_data = []\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     18\u001b[39m     max_len = \u001b[32m0\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m loss_values, legend_name \u001b[38;5;129;01min\u001b[39;00m line_list:\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'all'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "start = time.perf_counter()\n",
    "\n",
    "n_epochs= 5\n",
    "epoch_min = 0\n",
    "epoch_step = 1\n",
    "# n_epochs= 3\n",
    "# epoch_min = 0\n",
    "# epoch_step = 1\n",
    "\n",
    "sub_folder_ = ['GAN_practical']  # ['GAN_linear', 'GAN_practical', 'GAN_ls']\n",
    "\n",
    "\n",
    "for sub_folder in sub_folder_:\n",
    "    print(f\"Processing: {sub_folder}\")\n",
    "    w_dist = []\n",
    "    pad_pca_lda = []\n",
    "    pad_pca_logreg = []\n",
    "    pad_pca_svm = []\n",
    "    linear_interp = False\n",
    "    if sub_folder == 'GAN_linear':\n",
    "        linear_interp =True # flag to clip values that go beyond the estimated pilot (min, max)\n",
    "    ##\n",
    "    loader_H_true_train_source = class_dict_source[sub_folder].true_train\n",
    "    loader_H_input_train_source = class_dict_source[sub_folder].input_train\n",
    "    loader_H_true_val_source = class_dict_source[sub_folder].true_val\n",
    "    loader_H_input_val_source = class_dict_source[sub_folder].input_val\n",
    "    \n",
    "    loader_H_true_train_target = class_dict_target[sub_folder].true_train\n",
    "    loader_H_input_train_target = class_dict_target[sub_folder].input_train\n",
    "    loader_H_true_val_target = class_dict_target[sub_folder].true_val\n",
    "    loader_H_input_val_target = class_dict_target[sub_folder].input_val\n",
    "    ##\n",
    "    \n",
    "    # Distribution of original input training datasets (or before training)    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=100)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=100)\n",
    "    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=99)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=99)\n",
    "    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=95)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=95)\n",
    "\n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=90)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=90)\n",
    "\n",
    "    # Calculate Wasserstein-1 distance for original input training datasets (before training)\n",
    "    print(\"Calculating Wasserstein-1 distance for original input training datasets (before training)...\")\n",
    "    w_dist_epoc = plotfig.wasserstein_approximate(loader_H_input_train_source, loader_H_input_train_target)\n",
    "    w_dist.append(w_dist_epoc)\n",
    "    \n",
    "    # Calculate     PAD for original input training datasets with SVM\n",
    "    pad_svm = PAD.original_PAD(loader_H_input_train_source, loader_H_input_train_target)\n",
    "    print(f\"PAD = {pad_svm:.4f}\")\n",
    "    \n",
    "    # Calculate PCA_PAD for original input training datasets with PCA_SVM, PCA_LDA, PCA_LogReg\n",
    "    X_features_, y_features_ = PAD.extract_features_with_pca(loader_H_input_train_source, loader_H_input_train_target, pca_components=100)\n",
    "    pad_pca_svm_epoc = PAD.calc_pad_svm(X_features_, y_features_)\n",
    "    pad_pca_lda_epoc = PAD.calc_pad_lda(X_features_, y_features_)\n",
    "    pad_pca_logreg_epoc = PAD.calc_pad_logreg(X_features_, y_features_)\n",
    "    \n",
    "    pad_pca_lda.append(pad_pca_lda_epoc)\n",
    "    pad_pca_logreg.append(pad_pca_logreg_epoc)\n",
    "    pad_pca_svm.append(pad_pca_svm_epoc)\n",
    "    ## \n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(model_path + '/' + sub_folder +'/')):\n",
    "        os.makedirs(os.path.dirname(model_path + '/' + sub_folder + '/'))   # Domain_Adversarial/model/_/ver_/{sub_folder}\n",
    "\n",
    "    train_loss          = [] # (epoch,1)\n",
    "    train_est_loss      = [] \n",
    "    train_disc_loss     = [] \n",
    "    train_domain_loss   = []\n",
    "    train_est_loss_target = []\n",
    "    #    \n",
    "    val_loss, val_gan_disc_loss, val_domain_disc_loss,\\\n",
    "    val_est_loss_source, val_est_loss_target, val_est_loss,\\\n",
    "    source_acc, target_acc, acc,\\\n",
    "    nmse_val_source, nmse_val_target, nmse_val = [[] for _ in range(12)]\n",
    "    #\n",
    "    H_to_save = {}          # list to save to .mat file for H\n",
    "    perform_to_save = {}    # list to save to .mat file for nmse, losses,...\n",
    "\n",
    "    #  Use local GAN class instead of utils_GAN.GAN\n",
    "    model = GAN(n_subc=312, gen_l2=None, disc_l2=1e-5)  # l2 regularization for generator and discriminator\n",
    "    #  Fixed indentation issue\n",
    "    gen_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "    disc_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5, beta_2=0.9)  # WGAN-GP uses Adam optimizer with beta_1=0.5\n",
    "    #  No domain optimizer needed for JMMD\n",
    "    ####\n",
    "    optimizer = [gen_optimizer, disc_optimizer]  #  Only 2 optimizers for JMMD\n",
    "    ####\n",
    "    \n",
    "    flag = 1 # flag to plot and save H_true\n",
    "    epoc_pad = []    # epochs that calculating pad (return_features == True)\n",
    "    for epoch in range(n_epochs):\n",
    "        # ===================== Training =====================\n",
    "        loader_H_true_train_source.reset()\n",
    "        # loader_H_practical_train_source.reset()\n",
    "        loader_H_input_train_source.reset()\n",
    "        loader_H_true_train_target.reset()\n",
    "        # loader_H_practical_train_target.reset()\n",
    "        loader_H_input_train_target.reset()\n",
    "                \n",
    "        # loader_H = [loader_H_practical_train_source, loader_H_true_train_source, loader_H_practical_train_target, loader_H_true_train_target]\n",
    "        loader_H = [loader_H_input_train_source, loader_H_true_train_source, loader_H_input_train_target, loader_H_true_train_target]\n",
    "        \n",
    "        #  Only 2 loss functions needed for JMMD\n",
    "        loss_fn = [loss_fn_ce, loss_fn_bce]\n",
    "    \n",
    "        ##########################\n",
    "        if epoch in [int(n_epochs * r) for r in [0, 0.25, 0.5, 0.75]] or epoch == n_epochs-1:\n",
    "            # return_features == return features to calculate PAD\n",
    "            return_features = True\n",
    "            epoc_pad.append(epoch)\n",
    "        else:\n",
    "            return_features = False\n",
    "\n",
    "        ##########################\n",
    "        #  Already correctly calling train_step_wgan_gp_jmmd with proper parameters\n",
    "        train_step_output = train_step_wgan_gp_jmmd(model, loader_H, loss_fn, optimizer, lower_range=-1, save_features=True,\n",
    "                                adv_weight=adv_weight, est_weight=est_weight, jmmd_weight=domain_weight, linear_interp=linear_interp)\n",
    "        \n",
    "        train_epoc_loss_est        = train_step_output.avg_epoc_loss_est\n",
    "        train_epoc_loss_d          = train_step_output.avg_epoc_loss_d\n",
    "        train_epoc_loss_domain     = train_step_output.avg_epoc_loss_domain  # Now contains JMMD loss\n",
    "        train_epoc_loss            = train_step_output.avg_epoc_loss\n",
    "        train_epoc_loss_est_target = train_step_output.avg_epoc_loss_est_target\n",
    "                # train_epoc_loss        = total train loss = loss_est + lambda_jmmd * jmmd_loss\n",
    "                # train_epoc_loss_est    = loss in estimation network in source domain (labels available)\n",
    "                # train_epoc_loss_domain = JMMD loss (statistical distribution matching)\n",
    "                # train_epoc_loss_est_target - just to monitor - the machine can not calculate because no label available in source domain\n",
    "                # All are already calculated in average over training dataset (source/target - respectively)\n",
    "        print(\"Time\", time.perf_counter() - start, \"seconds\")\n",
    "        # Calculate PAD for the extracted features\n",
    "        if return_features and (domain_weight!=0):\n",
    "            features_source_file = \"features_source.h5\"\n",
    "            features_target_file = \"features_target.h5\"\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}\")\n",
    "            ## Calculate PCA_PAD for extracted features with PCA_SVM, PCA_LDA, PCA_LogReg\n",
    "            X_features, y_features = PAD.extract_features_with_pca(features_source_file, features_target_file, pca_components=100)\n",
    "            pad_svm_epoc = PAD.calc_pad_svm(X_features, y_features)\n",
    "            pad_pca_svm.append(pad_svm_epoc)\n",
    "            #\n",
    "            pad_lda_epoc = PAD.calc_pad_lda(X_features, y_features)\n",
    "            pad_pca_lda.append(pad_lda_epoc)\n",
    "            #\n",
    "            pad_logreg_epoc = PAD.calc_pad_logreg(X_features, y_features)\n",
    "            pad_pca_logreg.append(pad_logreg_epoc)\n",
    "            \n",
    "            ## Distribution of extracted features\n",
    "            plotfig.plotHist(features_source_file, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name=f'source_epoch_{epoch+1}', percent=99)\n",
    "            plotfig.plotHist(features_target_file, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name=f'target_epoch_{epoch+1}', percent=99)\n",
    "            #\n",
    "            plotfig.plotHist(features_source_file, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name=f'source_epoch_{epoch+1}', percent=100)\n",
    "            plotfig.plotHist(features_target_file, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name=f'target_epoch_{epoch+1}', percent=100)\n",
    "            #\n",
    "            # Calculate Wasserstein-1 distance for extracted features\n",
    "            # print(\"Calculating Wasserstein-1 distance for extracted features ...\")\n",
    "            # w_dist_epoc = plotfig.wasserstein_approximate(features_source_file, features_target_file)\n",
    "            # w_dist.append(w_dist_epoc)\n",
    "            \n",
    "\n",
    "            if os.path.exists(features_source_file):\n",
    "                os.remove(features_source_file)\n",
    "            if os.path.exists(features_target_file):\n",
    "                os.remove(features_target_file)\n",
    "            print(\"Time\", time.perf_counter() - start, \"seconds\")\n",
    "            \n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        train_loss.append(train_epoc_loss)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Training Loss: {train_epoc_loss:.6f}\")\n",
    "        #\n",
    "        train_est_loss.append(train_epoc_loss_est)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Estimation Loss (in Source domain): {train_epoc_loss_est:.6f}\")\n",
    "        #\n",
    "        train_disc_loss.append(train_epoc_loss_d)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Disc Loss (in Source domain): {train_epoc_loss_d:.6f}\")\n",
    "        #\n",
    "        train_domain_loss.append(train_epoc_loss_domain)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average JMMD Loss: {train_epoc_loss_domain:.6f}\")  #  Updated print message\n",
    "        #\n",
    "        train_est_loss_target.append(train_epoc_loss_est_target)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} For observation only - Average Estimation Loss in Target domain: {train_epoc_loss_est_target:.6f}\")\n",
    "        \n",
    "        \n",
    "        # ===================== Evaluation =====================\n",
    "        loader_H_true_val_source.reset()\n",
    "        loader_H_input_val_source.reset()\n",
    "        loader_H_true_val_target.reset()\n",
    "        loader_H_input_val_target.reset()\n",
    "        loader_H_eval = [loader_H_input_val_source, loader_H_true_val_source, loader_H_input_val_target, loader_H_true_val_target]\n",
    "\n",
    "        #  Only 2 loss functions needed for JMMD validation\n",
    "        loss_fn = [loss_fn_ce, loss_fn_bce]\n",
    "        \n",
    "        # eval_func = utils_UDA_FiLM.val_step\n",
    "        if (epoch==epoch_min) or (epoch+1>epoch_min and (epoch-epoch_min)%epoch_step==0) or epoch==n_epochs-1:\n",
    "            #  Already correctly calling val_step_wgan_gp_jmmd\n",
    "            H_sample, epoc_val_return = val_step_wgan_gp_jmmd(model, loader_H_eval, loss_fn, lower_range, \n",
    "                                            adv_weight=adv_weight, est_weight=est_weight, jmmd_weight=domain_weight, linear_interp=linear_interp)\n",
    "            visualize_H(H_sample, H_to_save, epoch, plotfig.figChan, flag, model_path, sub_folder, domain_weight=domain_weight)\n",
    "            flag = 0  # after the first epoch, no need to save H_true anymore\n",
    "            \n",
    "        else:\n",
    "            #  Already correctly calling val_step_wgan_gp_jmmd\n",
    "            _, epoc_val_return = val_step_wgan_gp_jmmd(model, loader_H_eval, loss_fn, lower_range, \n",
    "                                            adv_weight=adv_weight, est_weight=est_weight, jmmd_weight=domain_weight, linear_interp=linear_interp)\n",
    "        \n",
    "        post_val(epoc_val_return, epoch, n_epochs, val_est_loss, val_est_loss_source, val_loss, val_est_loss_target,\n",
    "            val_gan_disc_loss, val_domain_disc_loss, nmse_val_source, nmse_val_target, nmse_val, source_acc, target_acc, acc, domain_weight=domain_weight)\n",
    "        \n",
    "        \n",
    "        if (epoch==epoch_min) or (epoch+1>epoch_min and (epoch-epoch_min)%epoch_step==0) or epoch==n_epochs-1:\n",
    "            metrics = {'figLoss': plotfig.figLoss, 'savemat': savemat,\n",
    "                'train_loss': train_loss, 'train_est_loss': train_est_loss, 'train_domain_loss': train_domain_loss, 'train_est_loss_target': train_est_loss_target,\n",
    "                'val_est_loss': val_est_loss, 'val_est_loss_source': val_est_loss_source, 'val_loss': val_loss, 'val_est_loss_target': val_est_loss_target,\n",
    "                'val_gan_disc_loss': val_gan_disc_loss, 'val_domain_disc_loss': val_domain_disc_loss, 'source_acc': source_acc, 'target_acc': target_acc,\n",
    "                'acc': acc, 'nmse_val_source': nmse_val_source, 'nmse_val_target': nmse_val_target, 'nmse_val': nmse_val,\n",
    "                'pad_pca_svm': pad_pca_svm, 'pad_pca_lda': pad_pca_lda, 'pad_pca_logreg': pad_pca_logreg, 'epoc_pad': epoc_pad,\n",
    "                'pad_svm': pad_svm, 'train_disc_loss': train_disc_loss, 'domain_weight': domain_weight, 'optimizer': optimizer}\n",
    "\n",
    "            save_checkpoint(model, save_model, model_path, sub_folder, epoch, metrics)\n",
    "    \n",
    "    # end of epoch loop\n",
    "    # =====================            \n",
    "    # Save performances\n",
    "    # Save H matrix\n",
    "    savemat(model_path + '/' + sub_folder + '/H_visualize/H_trix.mat', H_to_save)\n",
    "\n",
    "# end of trainmode   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a59395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.75,\n",
       " 1.9166666666666665,\n",
       " 1.9166666666666665,\n",
       " 1.9166666666666665,\n",
       " 1.9583333333333335,\n",
       " 1.9583333333333335]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_pca_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc1ace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.75, 1.5, 1.2083333333333335, 1.375, 1.4583333333333335, 1.3333333333333335]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_pca_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b842dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoc_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7699aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.08333333333333304, 1.9583333333333335, 1.9583333333333335, 2.0, 2.0, 2.0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_pca_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2544db10",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmse_source_LI = []\n",
    "nmse_target_LI = []\n",
    "nmse_source_practical = []\n",
    "nmse_target_practical = []\n",
    "nmse_source_LI_GAN = []\n",
    "nmse_target_LI_GAN = []\n",
    "nmse_source_practical_GAN = []\n",
    "nmse_target_practical_GAN = []\n",
    "\n",
    "SNR_dB_ = np.arange(-15, 1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ebbbd1",
   "metadata": {},
   "source": [
    "-5 practical\n",
    "-5 linear\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
