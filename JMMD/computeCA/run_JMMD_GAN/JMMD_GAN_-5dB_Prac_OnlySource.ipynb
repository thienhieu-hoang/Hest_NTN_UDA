{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06f3793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/thien/Code/NTN/Hest_NTN_UDA/JMMD/computeCA/run_JMMD_GAN\n",
      "/home/thien/Code/NTN/Hest_NTN_UDA\n",
      "N_samp_source =  2048\n",
      "N_samp_target =  2048\n",
      "train_size =  96\n",
      "val_size =  16\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Source-Only WGAN-GP Training Script\n",
    "\n",
    "This script trains a WGAN-GP model using only the source domain data, without domain adaptation.\n",
    "- Training: Source domain training set\n",
    "- Validation: Source domain validation set  \n",
    "- Testing: Target domain validation set (to measure generalization performance)\n",
    "\n",
    "The model architecture remains the same, but no domain adaptation techniques (JMMD) are applied.\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from scipy.io import savemat\n",
    "import h5py\n",
    "\n",
    "# Add the root project directory\n",
    "try:\n",
    "    code_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    project_root = os.path.abspath(os.path.join(code_dir, '..', '..', '..'))\n",
    "except NameError:\n",
    "    # Running in Jupyter Notebook\n",
    "    code_dir = os.getcwd()\n",
    "    project_root = os.path.abspath(os.path.join(code_dir, '..', '..', '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "print(code_dir)\n",
    "print(project_root) # Hest_NTN_UDA/\n",
    "\n",
    "from Domain_Adversarial.helper import loader, plotfig, PAD\n",
    "from Domain_Adversarial.helper.utils import H5BatchLoader\n",
    "from Domain_Adversarial.helper.utils_GAN import visualize_H\n",
    "from JMMD.helper.utils_GAN import save_checkpoint_jmmd as save_checkpoint\n",
    "\n",
    "SNR = -5\n",
    "# source_data_file_path_label = os.path.abspath(os.path.join(code_dir, '..', 'generatedChan', 'OpenNTN','H_perfect.mat'))\n",
    "source_data_file_path = os.path.abspath(os.path.join(code_dir, '..', '..', '..', 'generatedChan', 'MATLAB', 'TDL_A', f'SNR_{SNR}dB', 'matlabNTN.mat'))\n",
    "target_data_file_path = os.path.abspath(os.path.join(code_dir, '..', '..', '..', 'generatedChan', 'MATLAB', 'TDL_C', f'SNR_{SNR}dB', 'matlabNTN.mat'))\n",
    "norm_approach = 'minmax' # can be set to 'std'\n",
    "lower_range = -1 \n",
    "    # if norm_approach = 'minmax': \n",
    "        # =  0 for scaling to  [0 1]\n",
    "        # = -1 for scaling to [-1 1]\n",
    "    # if norm_approach = 'std': can be any value, but need to be defined\n",
    "weights = {\n",
    "    # Core loss weights\n",
    "    'adv_weight': 0.005,        # GAN adversarial loss weight\n",
    "    'est_weight': 1.0,          # Estimation loss weight (main task)\n",
    "    'domain_weight': 0.0,      # No domain_weight since we're not doing domain adaptation\n",
    "    \n",
    "    # Smoothness regularization weights\n",
    "    'temporal_weight': 0.02,    # Temporal smoothness penalty\n",
    "    'frequency_weight': 0.1,    # Frequency smoothness penalty\n",
    "}\n",
    "\n",
    "if norm_approach == 'minmax':\n",
    "    if lower_range == 0:\n",
    "        norm_txt = 'Using min-max [0 1]'\n",
    "    elif lower_range ==-1:\n",
    "        norm_txt = 'Using min-max [-1 1]'\n",
    "elif norm_approach == 'no':\n",
    "    norm_txt = 'No'\n",
    "    \n",
    "# Paths to save\n",
    "idx_save_path = loader.find_incremental_filename(project_root + '/JMMD/model/GAN','ver', '_', '')\n",
    "\n",
    "save_model = 1\n",
    "model_path = project_root + '/JMMD/model/GAN/ver' + str(idx_save_path) + '_'\n",
    "# figure_path = code_dir + '/model/GAN/ver' + str(idx_save_path) + '_/figure'\n",
    "model_readme = model_path + '/readme.txt'\n",
    "\n",
    "batch_size=16\n",
    "\n",
    "# ============ Source data ==============\n",
    "source_file = h5py.File(source_data_file_path, 'r')\n",
    "H_true_source = source_file['H_perfect']\n",
    "N_samp_source = H_true_source.shape[0]\n",
    "print('N_samp_source = ', N_samp_source)\n",
    "\n",
    "# ============ Target data ==============\n",
    "target_file = h5py.File(target_data_file_path, 'r')\n",
    "H_true_target = target_file['H_perfect']\n",
    "N_samp_target = H_true_target.shape[0]\n",
    "print('N_samp_target = ', N_samp_target)\n",
    "\n",
    "# Store random state \n",
    "rng_state = np.random.get_state()\n",
    "\n",
    "# --- Set a temporary seed for reproducible split ---\n",
    "np.random.seed(1234)   # any fixed integer seed\n",
    "# Random but repeatable split\n",
    "indices_source = np.arange(N_samp_source)\n",
    "np.random.shuffle(indices_source)\n",
    "indices_target = np.arange(N_samp_target)\n",
    "np.random.shuffle(indices_target)\n",
    "# Restore previous random state (so other code stays random)\n",
    "np.random.set_state(rng_state)\n",
    "#\n",
    "train_size = int(np.floor(N_samp_source * 0.9) // batch_size * batch_size)\n",
    "val_size = N_samp_source - train_size\n",
    "\n",
    "# Repeat the indices to match the maximum number of samples\n",
    "N_samp = max(N_samp_source, N_samp_target) \n",
    "indices_source = np.resize(indices_source, N_samp)\n",
    "indices_target = np.resize(indices_target, N_samp)\n",
    "\n",
    "# =======================================================\n",
    "## Divide the indices into training and validation sets\n",
    "# indices_train_source = indices_source[:train_size]\n",
    "# indices_val_source   = indices_source[train_size:train_size + val_size]\n",
    "\n",
    "# indices_train_target = indices_target[:train_size]\n",
    "# indices_val_target   = indices_target[train_size:train_size + val_size]\n",
    "\n",
    "# to test code\n",
    "indices_train_source = indices_source[:96]\n",
    "indices_val_source = indices_source[2032:]\n",
    "indices_train_target = indices_target[:96]\n",
    "indices_val_target = indices_target[2032:]\n",
    "\n",
    "print('train_size = ', indices_train_source.shape[0])\n",
    "print('val_size = ', indices_val_source.shape[0])\n",
    "\n",
    "class DataLoaders:\n",
    "    def __init__(self, file, indices_train, indices_val, tag='prac', batch_size=32): \n",
    "        # tag = 'prac' or 'li' or 'ls'\n",
    "        self.true_train = H5BatchLoader(file, dataset_name='H_perfect', batch_size=batch_size, shuffled_indices=indices_train)\n",
    "        self.true_val = H5BatchLoader(file, dataset_name='H_perfect', batch_size=batch_size, shuffled_indices=indices_val)\n",
    "\n",
    "        self.input_train = H5BatchLoader(file, f'H_{tag}', batch_size=batch_size, shuffled_indices=indices_train)\n",
    "        self.input_val = H5BatchLoader(file, f'H_{tag}', batch_size=batch_size, shuffled_indices=indices_val)\n",
    "\n",
    "# Source domain\n",
    "class_dict_source = {\n",
    "    'GAN_practical': DataLoaders(source_file, indices_train_source, indices_val_source, tag='prac', batch_size=batch_size),\n",
    "    'GAN_linear': DataLoaders(source_file, indices_train_source, indices_val_source, tag='li', batch_size=batch_size),\n",
    "    'GAN_ls': DataLoaders(source_file, indices_train_source, indices_val_source, tag='ls', batch_size=batch_size)\n",
    "}\n",
    "\n",
    "# Target domain\n",
    "class_dict_target = {\n",
    "    'GAN_practical': DataLoaders(target_file, indices_train_target, indices_val_target, tag='prac', batch_size=batch_size),\n",
    "    'GAN_linear': DataLoaders(target_file, indices_train_target, indices_val_target, tag='li', batch_size=batch_size),\n",
    "    'GAN_ls': DataLoaders(target_file, indices_train_target, indices_val_target, tag='ls', batch_size=batch_size)\n",
    "}\n",
    "\n",
    "loss_fn_ce = tf.keras.losses.MeanSquaredError()  # Channel estimation loss (generator loss)\n",
    "loss_fn_bce = tf.keras.losses.BinaryCrossentropy(from_logits=False) # Binary cross-entropy loss for discriminator\n",
    "\n",
    "from JMMD.helper.utils_GAN import GAN\n",
    "from JMMD.helper.utils_GAN import train_step_wgan_gp_source_only, val_step_wgan_gp_source_only, post_val\n",
    "\n",
    "import time\n",
    "start = time.perf_counter()\n",
    "\n",
    "n_epochs= 5\n",
    "epoch_min = 0\n",
    "epoch_step = 1\n",
    "# n_epochs= 3\n",
    "# epoch_min = 0\n",
    "# epoch_step = 1\n",
    "\n",
    "sub_folder_ = ['GAN_practical']  # ['GAN_linear', 'GAN_practical', 'GAN_ls']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8b26fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: GAN_practical\n",
      "Calculating Wasserstein-1 distance for original input training datasets (before training)...\n",
      "X shape =  (192, 528)\n",
      "X1 shape =  (96, 528) y1 shape =  (96,)\n",
      "(96, 528) (96,)\n",
      "C: 0.01, Error rate: 0.5208\n",
      "C: 0.1, Error rate: 0.3125\n",
      "C: 0.5, Error rate: 0.1562\n",
      "C: 1.0, Error rate: 0.0938\n",
      "C: 2.0, Error rate: 0.0208\n",
      "C: 5.0, Error rate: 0.0104\n",
      "C: 10.0, Error rate: 0.0000\n",
      "C: 50.0, Error rate: 0.0000\n",
      "C: 100.0, Error rate: 0.0000\n",
      "C: 500.0, Error rate: 0.0000\n",
      "C: 1000.0, Error rate: 0.0000\n",
      "Best C: 10.0, Best error rate: 0.0000\n",
      "PAD = 2.0000\n",
      "PAD = 2.0000\n",
      "Fitted PCA on batch: source 96/96, target 96/96\n",
      "Reduced source shape: (96, 100), target shape: (96, 100)\n",
      "== C: 0.01, Error rate: 0.5208\n",
      "== C: 0.1, Error rate: 0.5208\n",
      "== C: 0.5, Error rate: 0.1146\n",
      "== C: 1.0, Error rate: 0.1042\n",
      "== C: 2.0, Error rate: 0.0938\n",
      "== C: 5.0, Error rate: 0.0938\n",
      "== C: 10.0, Error rate: 0.0938\n",
      "== C: 50.0, Error rate: 0.0938\n",
      "== C: 100.0, Error rate: 0.0938\n",
      "== C: 500.0, Error rate: 0.0938\n",
      "== C: 1000.0, Error rate: 0.0938\n",
      "Best C: 2.0, Best error rate: 0.0938\n",
      "============ PAD (SVM) = 1.6250\n",
      "LDA Error rate: 0.3229\n",
      "============ PAD (LDA) = 0.7083\n",
      "Logistic Regression Error rate: 0.1562\n",
      "============ PAD (LogReg) = 1.3750\n",
      "Time 115.70014920691028 seconds\n",
      "epoch 1/5 Average Training Loss: 3.728571\n",
      "epoch 1/5 Average Estimation Loss (in Source domain): 3.664840\n",
      "epoch 1/5 Average Disc Loss (in Source domain): 2867.074219\n",
      "epoch 1/5 Source-only training (No domain adaptation): 0.000000\n",
      "epoch 1/5 Testing performance on Target domain: 5.983915\n",
      "epoch 1/5 (Val) Weighted Total Loss: 17.253809\n",
      "epoch 1/5 (Val) Average Estimation Loss (mean): 4.336223\n",
      "epoch 1/5 (Val) Average Estimation Loss (Source): 4.336223\n",
      "epoch 1/5 (Val) GAN Discriminator Loss: 2583.517334\n",
      "epoch 1/5 (Val) NMSE (Source): 1.572398, NMSE (Target): 1.520139, NMSE (Mean): 1.572398\n",
      "epoch 1/5 (Val) Domain Accuracy (Average): 0.5000\n",
      "epoch 1/5 (Val) Smoothness Loss: 0.000000\n",
      "Value(False)\n",
      "Checkpoint saved at epoch 1: /home/thien/Code/NTN/Hest_NTN_UDA/JMMD/model/GAN/ver10_/GAN_practical/model//epoch_1-1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1,) and (0,)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 200\u001b[39m\n\u001b[32m    197\u001b[39m         all_metrics.update(train_metrics)  \u001b[38;5;66;03m# Add training metrics\u001b[39;00m\n\u001b[32m    198\u001b[39m         all_metrics.update(val_metrics)    \u001b[38;5;66;03m# Add validation metrics\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m         \u001b[43msave_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;66;03m# end of epoch loop\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;66;03m# =====================            \u001b[39;00m\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Save performances\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# Save H matrix\u001b[39;00m\n\u001b[32m    206\u001b[39m savemat(model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/H_visualize/H_trix.mat\u001b[39m\u001b[33m'\u001b[39m, H_to_save)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/NTN/Hest_NTN_UDA/JMMD/helper/utils_GAN.py:1320\u001b[39m, in \u001b[36msave_checkpoint_jmmd\u001b[39m\u001b[34m(model, save_model, model_path, sub_folder, epoch, metrics)\u001b[39m\n\u001b[32m   1316\u001b[39m \u001b[38;5;66;03m# Plot figures === save and overwrite at checkpoints\u001b[39;00m\n\u001b[32m   1317\u001b[39m figLoss(line_list=[(metrics[\u001b[33m'\u001b[39m\u001b[33mnmse_val_source\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mSource Domain\u001b[39m\u001b[33m'\u001b[39m), (metrics[\u001b[33m'\u001b[39m\u001b[33mnmse_val_target\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mTarget Domain\u001b[39m\u001b[33m'\u001b[39m)], xlabel=\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m, ylabel=\u001b[33m'\u001b[39m\u001b[33mNMSE\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1318\u001b[39m             title=\u001b[33m'\u001b[39m\u001b[33mNMSE in Validation\u001b[39m\u001b[33m'\u001b[39m, index_save=\u001b[32m1\u001b[39m, figure_save_path= model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/performance\u001b[39m\u001b[33m'\u001b[39m, fig_name=\u001b[33m'\u001b[39m\u001b[33mNMSE_val\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m \u001b[43mfigLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_est_loss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTrain Loss - Source\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_est_loss_source\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVal Loss - Source\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mval_est_loss_target\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mVal Loss - Target\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m            \u001b[49m\u001b[43mxlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mEpoch\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mylabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mLoss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTraining GAN Losses\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_save\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigure_save_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/performance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGAN_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1324\u001b[39m figLoss(line_list=[(metrics[\u001b[33m'\u001b[39m\u001b[33mtrain_est_loss\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mGAN Generate Loss\u001b[39m\u001b[33m'\u001b[39m), (metrics[\u001b[33m'\u001b[39m\u001b[33mtrain_disc_loss\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mGAN Discriminator Loss\u001b[39m\u001b[33m'\u001b[39m)], xlabel=\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m, ylabel=\u001b[33m'\u001b[39m\u001b[33mLoss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1325\u001b[39m             title=\u001b[33m'\u001b[39m\u001b[33mTraining GAN Losses\u001b[39m\u001b[33m'\u001b[39m, index_save=\u001b[32m1\u001b[39m, figure_save_path= model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/performance\u001b[39m\u001b[33m'\u001b[39m, fig_name=\u001b[33m'\u001b[39m\u001b[33mGAN_train\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1326\u001b[39m figLoss(line_list=[(metrics[\u001b[33m'\u001b[39m\u001b[33mtrain_loss\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m'\u001b[39m), (metrics[\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m'\u001b[39m\u001b[33mValidating\u001b[39m\u001b[33m'\u001b[39m)], xlabel=\u001b[33m'\u001b[39m\u001b[33mEpoch\u001b[39m\u001b[33m'\u001b[39m, ylabel=\u001b[33m'\u001b[39m\u001b[33mTotal Loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1327\u001b[39m             title=\u001b[33m'\u001b[39m\u001b[33mTraining and Validating Total Loss\u001b[39m\u001b[33m'\u001b[39m, index_save=\u001b[32m1\u001b[39m, figure_save_path= model_path + \u001b[33m'\u001b[39m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m + sub_folder + \u001b[33m'\u001b[39m\u001b[33m/performance\u001b[39m\u001b[33m'\u001b[39m, fig_name=\u001b[33m'\u001b[39m\u001b[33mLoss_total\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/NTN/Hest_NTN_UDA/Domain_Adversarial/helper/plotfig.py:27\u001b[39m, in \u001b[36mfigLoss\u001b[39m\u001b[34m(line_list, index_save, figure_save_path, fig_show, fig_name, xlabel, ylabel, title, x)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m loss_values, legend_name \u001b[38;5;129;01min\u001b[39;00m line_list:\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         \u001b[43mplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlegend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m         max_len = \u001b[38;5;28mmax\u001b[39m(max_len, \u001b[38;5;28mlen\u001b[39m(loss_values))\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TF_py311/lib/python3.11/site-packages/matplotlib/pyplot.py:3827\u001b[39m, in \u001b[36mplot\u001b[39m\u001b[34m(scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   3819\u001b[39m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes.plot)\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mplot\u001b[39m(\n\u001b[32m   3821\u001b[39m     *args: \u001b[38;5;28mfloat\u001b[39m | ArrayLike | \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3825\u001b[39m     **kwargs,\n\u001b[32m   3826\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[32m-> \u001b[39m\u001b[32m3827\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3828\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3829\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3831\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3832\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3833\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TF_py311/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1777\u001b[39m, in \u001b[36mAxes.plot\u001b[39m\u001b[34m(self, scalex, scaley, data, *args, **kwargs)\u001b[39m\n\u001b[32m   1534\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1535\u001b[39m \u001b[33;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[32m   1536\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1774\u001b[39m \u001b[33;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1776\u001b[39m kwargs = cbook.normalize_kwargs(kwargs, mlines.Line2D)\n\u001b[32m-> \u001b[39m\u001b[32m1777\u001b[39m lines = [*\u001b[38;5;28mself\u001b[39m._get_lines(\u001b[38;5;28mself\u001b[39m, *args, data=data, **kwargs)]\n\u001b[32m   1778\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[32m   1779\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_line(line)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TF_py311/lib/python3.11/site-packages/matplotlib/axes/_base.py:297\u001b[39m, in \u001b[36m_process_plot_var_args.__call__\u001b[39m\u001b[34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[39m\n\u001b[32m    295\u001b[39m     this += args[\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     args = args[\u001b[32m1\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/TF_py311/lib/python3.11/site-packages/matplotlib/axes/_base.py:494\u001b[39m, in \u001b[36m_process_plot_var_args._plot_args\u001b[39m\u001b[34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[39m\n\u001b[32m    491\u001b[39m     axes.yaxis.update_units(y)\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.shape[\u001b[32m0\u001b[39m] != y.shape[\u001b[32m0\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y must have same first dimension, but \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    495\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    496\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x.ndim > \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y.ndim > \u001b[32m2\u001b[39m:\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mx and y can be no greater than 2D, but have \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    498\u001b[39m                      \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: x and y must have same first dimension, but have shapes (1,) and (0,)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAzoAAAGsCAYAAAAVEdLDAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIY5JREFUeJzt3X90VvV9wPHPE5CEAgk/akFCqBWdsWrwB5PGnU47Yv3Bschx68rQWI6rY3JOce0ccqR1tHNJC3M6nRyKetqpLB2WurNWxyxKWysCgrEorXNrVyI/NzsSQAmY3P3RmZqahDz5QeTr63XOPfa5z/fmfu/JPY++e597k8uyLAsAAICEFAz0BAAAAPqa0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5Awe6Al0R2tra+zcuTNGjBgRuVxuoKcDAAAMkCzLYv/+/TF+/PgoKOj8us1xETo7d+6MsrKygZ4GAADwLtHQ0BATJkzo9P3jInRGjBgREb86mOLi4gGeDQAAMFCampqirKysrRE6c1yEzltfVysuLhY6AADAUW9p8TACAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEhOr0KntrY2crlc3HTTTZ2OWb16dUyZMiVGjhwZw4YNi3POOScefPDB3uwWAACgS4N7uuGmTZti+fLlUVFR0eW40aNHx6233hrl5eUxZMiQ+M53vhNz5syJD3zgA3HppZf2dPcAAACd6tEVnQMHDsTs2bNjxYoVMWrUqC7HXnzxxTFz5sw444wzYtKkSTF//vyoqKiIp59+ukcTBgAAOJoehc68efNi+vTpUVVVldd2WZbF2rVr4+WXX47f/d3f7XRcc3NzNDU1tVsAAAC6K++vrtXV1cWWLVti06ZN3d6msbExSktLo7m5OQYNGhT33ntvXHLJJZ2Or6mpicWLF+c7NQAAgIjIM3QaGhpi/vz58cQTT0RRUVG3txsxYkTU19fHgQMHYu3atfG5z30uTjnllLj44os7HL9w4cL43Oc+1/a6qakpysrK8pkqAADwHpbLsizr7uBHH300Zs6cGYMGDWpb19LSErlcLgoKCtqu2BzNH//xH0dDQ0OsWbOmW/ttamqKkpKSaGxsjOLi4u5OFwAASEx32yCvKzrTpk2LrVu3tls3Z86cKC8vjwULFnQrciIiWltbo7m5OZ9dAwAAdFteoTNixIg466yz2q0bNmxYjBkzpm19dXV1lJaWRk1NTUT86n6bKVOmxKRJk6K5uTkee+yxePDBB2PZsmV9dAgAAADt9fjv6HRm+/btUVDw64e5HTx4MG688cZ49dVXY+jQoVFeXh4PPfRQ/OEf/mFf7xoAACAi8rxHZ6C4RwcAAIjofhv06O/oAAAAvJsJHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5PQqdGprayOXy8VNN93U6ZgVK1bERz/60Rg1alSMGjUqqqqqYuPGjb3ZLQAAQJd6HDqbNm2K5cuXR0VFRZfj1q1bF7NmzYqnnnoq1q9fH2VlZfHxj388duzY0dNdAwAAdKlHoXPgwIGYPXt2rFixIkaNGtXl2IcffjhuvPHGOOecc6K8vDzuu+++aG1tjbVr1/ZowgAAAEfTo9CZN29eTJ8+PaqqqvLe9vXXX48jR47E6NGjOx3T3NwcTU1N7RYAAIDuGpzvBnV1dbFly5bYtGlTj3a4YMGCGD9+fJeRVFNTE4sXL+7RzwcAAMjrik5DQ0PMnz8/Hn744SgqKsp7Z7W1tVFXVxff/va3u9x+4cKF0djY2LY0NDTkvS8AAOC9K5dlWdbdwY8++mjMnDkzBg0a1LaupaUlcrlcFBQURHNzc7v33m7p0qXxV3/1V/G9730vpkyZktckm5qaoqSkJBobG6O4uDivbQEAgHR0tw3y+uratGnTYuvWre3WzZkzJ8rLy2PBggWdRs5Xv/rVuP3222PNmjV5Rw4AAEC+8gqdESNGxFlnndVu3bBhw2LMmDFt66urq6O0tDRqamoiIuIrX/lKfPGLX4yVK1fGySefHLt3746IiOHDh8fw4cP74hgAAADa6dUfDO3I9u3bY9euXW2vly1bFocPH47f//3fj5NOOqltWbp0aV/vGgAAICLyvEdnoLhHBwAAiOh+G/T5FR0AAICBJnQAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJLTq9Cpra2NXC4XN910U6djXnrppbj66qvj5JNPjlwuF3feeWdvdgkAAHBUPQ6dTZs2xfLly6OioqLLca+//nqccsopUVtbG+PGjevp7gAAALqtR6Fz4MCBmD17dqxYsSJGjRrV5djf/u3fjiVLlsSnPvWpKCws7NEkAQAA8tGj0Jk3b15Mnz49qqqq+no+ERHR3NwcTU1N7RYAAIDuGpzvBnV1dbFly5bYtGlTf8wnIiJqampi8eLF/fbzAQCAtOV1RaehoSHmz58fDz/8cBQVFfXXnGLhwoXR2NjYtjQ0NPTbvgAAgPTkdUVn8+bNsXfv3jjvvPPa1rW0tMQPfvCDuOeee6K5uTkGDRrU60kVFha6nwcAAOixvEJn2rRpsXXr1nbr5syZE+Xl5bFgwYI+iRwAAIDeyit0RowYEWeddVa7dcOGDYsxY8a0ra+uro7S0tKoqamJiIjDhw/Htm3b2v73jh07or6+PoYPHx6nnnpqXxwDAABAO3k/jOBotm/fHgUFv771Z+fOnXHuuee2vV66dGksXbo0Lrrooli3bl1f7x4AACByWZZlAz2Jo2lqaoqSkpJobGyM4uLigZ4OAAAwQLrbBj36OzoAAADvZkIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5vQqd2trayOVycdNNN3U5btWqVVFeXh5FRUVx9tlnx2OPPdab3QIAAHSpx6GzadOmWL58eVRUVHQ57plnnolZs2bF9ddfH88//3xcddVVcdVVV8WLL77Y010DAAB0qUehc+DAgZg9e3asWLEiRo0a1eXYu+66Ky677LK4+eab44wzzogvf/nLcd5558U999zTowkDAAAcTY9CZ968eTF9+vSoqqo66tj169e/Y9yll14a69ev73Sb5ubmaGpqarcAAAB01+B8N6irq4stW7bEpk2bujV+9+7dMXbs2Hbrxo4dG7t37+50m5qamli8eHG+UwMAAIiIPK/oNDQ0xPz58+Phhx+OoqKi/ppTLFy4MBobG9uWhoaGftsXAACQnryu6GzevDn27t0b5513Xtu6lpaW+MEPfhD33HNPNDc3x6BBg9ptM27cuNizZ0+7dXv27Ilx48Z1up/CwsIoLCzMZ2oAAABt8rqiM23atNi6dWvU19e3LVOmTInZs2dHfX39OyInIqKysjLWrl3bbt0TTzwRlZWVvZs5AABAJ/K6ojNixIg466yz2q0bNmxYjBkzpm19dXV1lJaWRk1NTUREzJ8/Py666KL4m7/5m5g+fXrU1dXFc889F1/72tf66BAAAADa69UfDO3I9u3bY9euXW2vL7zwwli5cmV87Wtfi8mTJ8cjjzwSjz766DuCCQAAoK/ksizLBnoSR9PU1BQlJSXR2NgYxcXFAz0dAABggHS3Dfr8ig4AAMBAEzoAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQHKEDAAAkR+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMnJK3SWLVsWFRUVUVxcHMXFxVFZWRmPP/54p+OPHDkSX/rSl2LSpElRVFQUkydPjn/913/t9aQBAAC6klfoTJgwIWpra2Pz5s3x3HPPxe/93u/FjBkz4qWXXupw/KJFi2L58uVx9913x7Zt22Lu3Lkxc+bMeP755/tk8gAAAB3JZVmW9eYHjB49OpYsWRLXX3/9O94bP3583HrrrTFv3ry2dVdffXUMHTo0HnrooW7vo6mpKUpKSqKxsTGKi4t7M10AAOA41t02GNzTHbS0tMSqVavi4MGDUVlZ2eGY5ubmKCoqardu6NCh8fTTT3f5s5ubm6O5ubntdVNTU0+nCQAAvAfl/TCCrVu3xvDhw6OwsDDmzp0b3/72t+PDH/5wh2MvvfTSuOOOO+KVV16J1tbWeOKJJ2L16tWxa9euLvdRU1MTJSUlbUtZWVm+0wQAAN7D8v7q2uHDh2P79u3R2NgYjzzySNx3333x/e9/v8PY+e///u/4zGc+E//yL/8SuVwuJk2aFFVVVfHAAw/EG2+80ek+OrqiU1ZW5qtrAADwHtfdr671+h6dqqqqmDRpUixfvrzTMYcOHYrXXnstxo8fH7fcckt85zvf6fQBBh1xjw4AABDR/Tbo9d/RaW1tbXf1pSNFRUVRWloab775ZnzrW9+KGTNm9Ha3AAAAncrrYQQLFy6Myy+/PCZOnBj79++PlStXxrp162LNmjUREVFdXR2lpaVRU1MTEREbNmyIHTt2xDnnnBM7duyIv/zLv4zW1tb4i7/4i74/EgAAgP+XV+js3bs3qqurY9euXVFSUhIVFRWxZs2auOSSSyIiYvv27VFQ8OuLRIcOHYpFixbFz372sxg+fHhcccUV8eCDD8bIkSP79CAAAADertf36BwL7tEBAAAijuE9OgAAAO82QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASE5eobNs2bKoqKiI4uLiKC4ujsrKynj88ce73ObOO++M008/PYYOHRplZWXxZ3/2Z3Ho0KFeTRoAAKArg/MZPGHChKitrY3TTjstsiyLb3zjGzFjxox4/vnn48wzz3zH+JUrV8Ytt9wSDzzwQFx44YXx7//+7/HpT386crlc3HHHHX12EAAAAG+XV+hceeWV7V7ffvvtsWzZsnj22Wc7DJ1nnnkmfud3fif+6I/+KCIiTj755Jg1a1Zs2LChy/00NzdHc3Nz2+umpqZ8pgkAALzH9fgenZaWlqirq4uDBw9GZWVlh2MuvPDC2Lx5c2zcuDEiIn72s5/FY489FldccUWXP7umpiZKSkralrKysp5OEwAAeA/KZVmW5bPB1q1bo7KyMg4dOhTDhw+PlStXdhkuf/d3fxd//ud/HlmWxZtvvhlz586NZcuWdbmPjq7olJWVRWNjYxQXF+czXQAAICFNTU1RUlJy1DbI+4rO6aefHvX19bFhw4b40z/907juuuti27ZtHY5dt25d/PVf/3Xce++9sWXLlli9enV897vfjS9/+ctd7qOwsLDtgQdvLQAAAN2V9xWd31RVVRWTJk2K5cuXv+O9j370o/GRj3wklixZ0rbuoYceihtuuCEOHDgQBQXd66zuVhsAAJC2frui85taW1vbfc3s7V5//fV3xMygQYMiIqKXfQUAANCpvJ66tnDhwrj88stj4sSJsX///li5cmWsW7cu1qxZExER1dXVUVpaGjU1NRHxq6e03XHHHXHuuefG1KlT4z/+4z/iC1/4Qlx55ZVtwQMAANDX8gqdvXv3RnV1dezatStKSkqioqIi1qxZE5dccklERGzfvr3dFZxFixZFLpeLRYsWxY4dO+LEE0+MK6+8Mm6//fa+PQoAAIC36fU9OseCe3QAAICIY3iPDgAAwLuN0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASE5eobNs2bKoqKiI4uLiKC4ujsrKynj88cc7HX/xxRdHLpd7xzJ9+vReTxwAAKAzg/MZPGHChKitrY3TTjstsiyLb3zjGzFjxox4/vnn48wzz3zH+NWrV8fhw4fbXr/22msxefLk+IM/+IPezxwAAKATeYXOlVde2e717bffHsuWLYtnn322w9AZPXp0u9d1dXXxvve976ih09zcHM3NzW2vm5qa8pkmAADwHtfje3RaWlqirq4uDh48GJWVld3a5v77749PfepTMWzYsC7H1dTURElJSdtSVlbW02kCAADvQbksy7J8Nti6dWtUVlbGoUOHYvjw4bFy5cq44oorjrrdxo0bY+rUqbFhw4a44IILuhzb0RWdsrKyaGxsjOLi4nymCwAAJKSpqSlKSkqO2gZ5fXUtIuL000+P+vr6aGxsjEceeSSuu+66+P73vx8f/vCHu9zu/vvvj7PPPvuokRMRUVhYGIWFhflODQAAICJ68NW1IUOGxKmnnhrnn39+1NTUxOTJk+Ouu+7qcpuDBw9GXV1dXH/99T2eKAAAQHf1+u/otLa2tvuaWUdWrVoVzc3Ncc011/R2dwAAAEeV11fXFi5cGJdffnlMnDgx9u/fHytXrox169bFmjVrIiKiuro6SktLo6ampt12999/f1x11VUxZsyYvps5AABAJ/IKnb1790Z1dXXs2rUrSkpKoqKiItasWROXXHJJRERs3749CgraXyR6+eWX4+mnn45/+7d/67tZAwAAdCHvp64NhO4+WQEAAEhbd9ug1/foAAAAvNsIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASI7QAQAAkiN0AACA5AgdAAAgOUIHAABIjtABAACSI3QAAIDkCB0AACA5QgcAAEiO0AEAAJIjdAAAgOQIHQAAIDlCBwAASM7ggZ5Ad2RZFhERTU1NAzwTAABgIL3VBG81QmeOi9DZv39/RESUlZUN8EwAAIB3g/3790dJSUmn7+eyo6XQu0Bra2vs3LkzRowYEblcbqCnQweampqirKwsGhoaori4eKCnw3HAOUO+nDPkyzlDvpwzx4csy2L//v0xfvz4KCjo/E6c4+KKTkFBQUyYMGGgp0E3FBcX+2AgL84Z8uWcIV/OGfLlnHn36+pKzls8jAAAAEiO0AEAAJIjdOgThYWFcdttt0VhYeFAT4XjhHOGfDlnyJdzhnw5Z9JyXDyMAAAAIB+u6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6dNsvf/nLmD17dhQXF8fIkSPj+uuvjwMHDnS5zaFDh2LevHkxZsyYGD58eFx99dWxZ8+eDse+9tprMWHChMjlcrFv375+OAKOtf44Z1544YWYNWtWlJWVxdChQ+OMM86Iu+66q78PhX7y93//93HyySdHUVFRTJ06NTZu3Njl+FWrVkV5eXkUFRXF2WefHY899li797Msiy9+8Ytx0kknxdChQ6OqqipeeeWV/jwEjrG+PGeOHDkSCxYsiLPPPjuGDRsW48ePj+rq6ti5c2d/HwbHUF9/zrzd3LlzI5fLxZ133tnHs6ZPZNBNl112WTZ58uTs2WefzX74wx9mp556ajZr1qwut5k7d25WVlaWrV27Nnvuueeyj3zkI9mFF17Y4dgZM2Zkl19+eRYR2f/+7//2wxFwrPXHOXP//fdnn/3sZ7N169Zl//mf/5k9+OCD2dChQ7O77767vw+HPlZXV5cNGTIke+CBB7KXXnop+8xnPpONHDky27NnT4fjf/SjH2WDBg3KvvrVr2bbtm3LFi1alJ1wwgnZ1q1b28bU1tZmJSUl2aOPPpq98MIL2Sc+8YnsQx/6UPbGG28cq8OiH/X1ObNv376sqqoq++Y3v5n99Kc/zdavX59dcMEF2fnnn38sD4t+1B+fM29ZvXp1Nnny5Gz8+PHZ3/7t3/bzkdATQodu2bZtWxYR2aZNm9rWPf7441kul8t27NjR4Tb79u3LTjjhhGzVqlVt637yk59kEZGtX7++3dh77703u+iii7K1a9cKnUT09znzdjfeeGP2sY99rO8mzzFxwQUXZPPmzWt73dLSko0fPz6rqanpcPwnP/nJbPr06e3WTZ06NfuTP/mTLMuyrLW1NRs3bly2ZMmStvf37duXFRYWZv/4j//YD0fAsdbX50xHNm7cmEVE9otf/KJvJs2A6q9z5tVXX81KS0uzF198MfvgBz8odN6lfHWNblm/fn2MHDkypkyZ0rauqqoqCgoKYsOGDR1us3nz5jhy5EhUVVW1rSsvL4+JEyfG+vXr29Zt27YtvvSlL8U//MM/REGBUzIV/XnO/KbGxsYYPXp0302efnf48OHYvHlzu991QUFBVFVVdfq7Xr9+fbvxERGXXnpp2/if//znsXv37nZjSkpKYurUqV2ePxwf+uOc6UhjY2PkcrkYOXJkn8ybgdNf50xra2tce+21cfPNN8eZZ57ZP5OnT/ivSrpl9+7d8YEPfKDdusGDB8fo0aNj9+7dnW4zZMiQd/zLYuzYsW3bNDc3x6xZs2LJkiUxceLEfpk7A6O/zpnf9Mwzz8Q3v/nNuOGGG/pk3hwb//M//xMtLS0xduzYduu7+l3v3r27y/Fv/TOfn8nxoz/Omd906NChWLBgQcyaNSuKi4v7ZuIMmP46Z77yla/E4MGD47Of/WzfT5o+JXTe42655ZbI5XJdLj/96U/7bf8LFy6MM844I6655pp+2wd9a6DPmbd78cUXY8aMGXHbbbfFxz/+8WOyTyBNR44ciU9+8pORZVksW7ZsoKfDu9TmzZvjrrvuiq9//euRy+UGejocxeCBngAD6/Of/3x8+tOf7nLMKaecEuPGjYu9e/e2W//mm2/GL3/5yxg3blyH240bNy4OHz4c+/bta/f/0O/Zs6dtmyeffDK2bt0ajzzySET86olJERHvf//749Zbb43Fixf38MjoLwN9zrxl27ZtMW3atLjhhhti0aJFPToWBs773//+GDRo0DuewtjR7/ot48aN63L8W//cs2dPnHTSSe3GnHPOOX04ewZCf5wzb3krcn7xi1/Ek08+6WpOIvrjnPnhD38Ye/fubfctlJaWlvj85z8fd955Z/zXf/1X3x4EveKKznvciSeeGOXl5V0uQ4YMicrKyti3b19s3ry5bdsnn3wyWltbY+rUqR3+7PPPPz9OOOGEWLt2bdu6l19+ObZv3x6VlZUREfGtb30rXnjhhaivr4/6+vq47777IuJXHyTz5s3rxyOnpwb6nImIeOmll+JjH/tYXHfddXH77bf338HSb4YMGRLnn39+u991a2trrF27tt3v+u0qKyvbjY+IeOKJJ9rGf+hDH4px48a1G9PU1BQbNmzo9Gdy/OiPcybi15HzyiuvxPe+970YM2ZM/xwAx1x/nDPXXntt/PjHP27775b6+voYP3583HzzzbFmzZr+Oxh6ZqCfhsDx47LLLsvOPffcbMOGDdnTTz+dnXbaae0eFfzqq69mp59+erZhw4a2dXPnzs0mTpyYPfnkk9lzzz2XVVZWZpWVlZ3u46mnnvLUtYT0xzmzdevW7MQTT8yuueaabNeuXW3L3r17j+mx0Xt1dXVZYWFh9vWvfz3btm1bdsMNN2QjR47Mdu/enWVZll177bXZLbfc0jb+Rz/6UTZ48OBs6dKl2U9+8pPstttu6/Dx0iNHjsz++Z//Ofvxj3+czZgxw+OlE9LX58zhw4ezT3ziE9mECROy+vr6dp8pzc3NA3KM9K3++Jz5TZ669u4ldOi21157LZs1a1Y2fPjwrLi4OJszZ062f//+tvd//vOfZxGRPfXUU23r3njjjezGG2/MRo0alb3vfe/LZs6cme3atavTfQidtPTHOXPbbbdlEfGO5YMf/OAxPDL6yt13351NnDgxGzJkSHbBBRdkzz77bNt7F110UXbddde1G/9P//RP2W/91m9lQ4YMyc4888zsu9/9brv3W1tbsy984QvZ2LFjs8LCwmzatGnZyy+/fCwOhWOkL8+Ztz6DOlre/rnE8a2vP2d+k9B598pl2f/fFAEAAJAI9+gAAADJEToAAEByhA4AAJAcoQMAACRH6AAAAMkROgAAQHKEDgAAkByhAwAAJEfoAAAAyRE6AABAcoQOAACQnP8D06JtABjkeGIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for sub_folder in sub_folder_:\n",
    "    print(f\"Processing: {sub_folder}\")\n",
    "    pad_metrics = {\n",
    "        'pad_pca_lda': {},      # Dictionary to store LDA PAD values by epoch\n",
    "        'pad_pca_logreg': {},   # Dictionary to store LogReg PAD values by epoch\n",
    "        'pad_pca_svm': {},      # Dictionary to store SVM PAD values by epoch\n",
    "        'w_dist': {}            # Dictionary to store Wasserstein distances by epoch\n",
    "    }\n",
    "    linear_interp = False\n",
    "    if sub_folder == 'GAN_linear':\n",
    "        linear_interp =True # flag to clip values that go beyond the estimated pilot (min, max)\n",
    "    ##\n",
    "    loader_H_true_train_source = class_dict_source[sub_folder].true_train\n",
    "    loader_H_input_train_source = class_dict_source[sub_folder].input_train\n",
    "    loader_H_true_val_source = class_dict_source[sub_folder].true_val\n",
    "    loader_H_input_val_source = class_dict_source[sub_folder].input_val\n",
    "    \n",
    "    loader_H_true_train_target = class_dict_target[sub_folder].true_train\n",
    "    loader_H_input_train_target = class_dict_target[sub_folder].input_train\n",
    "    loader_H_true_val_target = class_dict_target[sub_folder].true_val\n",
    "    loader_H_input_val_target = class_dict_target[sub_folder].input_val\n",
    "    ##\n",
    "    \n",
    "    # Distribution of original input training datasets (or before training)    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=100)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=100)\n",
    "    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=99)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=99)\n",
    "    \n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=95)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=95)\n",
    "\n",
    "    plotfig.plotHist(loader_H_input_train_source, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='source_beforeTrain', percent=90)\n",
    "    plotfig.plotHist(loader_H_input_train_target, fig_show = False, save_path=f\"{model_path}/{sub_folder}/Distribution/\", name='target_beforeTrain', percent=90)\n",
    "\n",
    "    # Calculate Wasserstein-1 distance for original input training datasets (before training)\n",
    "    print(\"Calculating Wasserstein-1 distance for original input training datasets (before training)...\")\n",
    "    w_dist_epoc = plotfig.wasserstein_approximate(loader_H_input_train_source, loader_H_input_train_target)\n",
    "    pad_metrics['w_dist']['before_training'] = w_dist_epoc\n",
    "    \n",
    "    # Calculate     PAD for original input training datasets with SVM\n",
    "    pad_svm = PAD.original_PAD(loader_H_input_train_source, loader_H_input_train_target)\n",
    "    print(f\"PAD = {pad_svm:.4f}\")\n",
    "    \n",
    "    # Calculate PCA_PAD for original input training datasets with PCA_SVM, PCA_LDA, PCA_LogReg\n",
    "    X_features_, y_features_ = PAD.extract_features_with_pca(loader_H_input_train_source, loader_H_input_train_target, pca_components=100)\n",
    "    pad_pca_svm_epoc = PAD.calc_pad_svm(X_features_, y_features_)\n",
    "    pad_pca_lda_epoc = PAD.calc_pad_lda(X_features_, y_features_)\n",
    "    pad_pca_logreg_epoc = PAD.calc_pad_logreg(X_features_, y_features_)\n",
    "    \n",
    "    pad_metrics['pad_pca_lda']['before_training'] = pad_pca_lda_epoc\n",
    "    pad_metrics['pad_pca_logreg']['before_training'] = pad_pca_logreg_epoc  \n",
    "    pad_metrics['pad_pca_svm']['before_training'] = pad_pca_svm_epoc\n",
    "    ## \n",
    "    \n",
    "    if not os.path.exists(os.path.dirname(model_path + '/' + sub_folder +'/')):\n",
    "        os.makedirs(os.path.dirname(model_path + '/' + sub_folder + '/'))   # Domain_Adversarial/model/_/ver_/{sub_folder}\n",
    "\n",
    "    #\n",
    "    train_metrics = {\n",
    "        'train_loss': [],           # total training loss \n",
    "        'train_est_loss': [],       # estimation loss\n",
    "        'train_disc_loss': [],      # discriminator loss\n",
    "        'train_domain_loss': [],    # JMMD loss (replaces domain loss)\n",
    "        'train_est_loss_target': [] # target estimation loss (monitoring)\n",
    "    }\n",
    "    \n",
    "    # \n",
    "    val_metrics = {\n",
    "        'val_loss': [],                 # total validation loss\n",
    "        'val_gan_disc_loss': [],        # GAN discriminator loss\n",
    "        'val_domain_disc_loss': [],     # JMMD loss (replaces domain discriminator)\n",
    "        'val_est_loss_source': [],      # source estimation loss\n",
    "        'val_est_loss_target': [],      # target estimation loss  \n",
    "        'val_est_loss': [],             # average estimation loss\n",
    "        'source_acc': [],               # source domain accuracy (placeholder for JMMD)\n",
    "        'target_acc': [],               # target domain accuracy (placeholder for JMMD)\n",
    "        'acc': [],                      # average accuracy (placeholder for JMMD)\n",
    "        'nmse_val_source': [],          # source NMSE\n",
    "        'nmse_val_target': [],          # target NMSE\n",
    "        'nmse_val': [],                  # average NMSE\n",
    "        'val_smoothness_loss': []\n",
    "    }\n",
    "    #\n",
    "    H_to_save = {}          # list to save to .mat file for H\n",
    "    perform_to_save = {}    # list to save to .mat file for nmse, losses,...\n",
    "\n",
    "    # \n",
    "    model = GAN(n_subc=312, gen_l2=None, disc_l2=1e-5)  # l2 regularization for generator and discriminator\n",
    "    # \n",
    "    gen_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5, beta_2=0.9)\n",
    "    disc_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5, beta_1=0.5, beta_2=0.9)  # WGAN-GP uses Adam optimizer with beta_1=0.5\n",
    "    # \n",
    "    ####\n",
    "    optimizer = [gen_optimizer, disc_optimizer]  # \n",
    "    ####\n",
    "    \n",
    "    flag = 1 # flag to plot and save H_true\n",
    "    epoc_pad = []    # epochs that calculating pad (return_features == True)\n",
    "    for epoch in range(n_epochs):\n",
    "        # ===================== Training =====================\n",
    "        loader_H_true_train_source.reset()\n",
    "        # loader_H_practical_train_source.reset()\n",
    "        loader_H_input_train_source.reset()\n",
    "        loader_H_true_train_target.reset()\n",
    "        # loader_H_practical_train_target.reset()\n",
    "        loader_H_input_train_target.reset()\n",
    "                \n",
    "        # loader_H = [loader_H_practical_train_source, loader_H_true_train_source, loader_H_practical_train_target, loader_H_true_train_target]\n",
    "        loader_H = [loader_H_input_train_source, loader_H_true_train_source, loader_H_input_train_target, loader_H_true_train_target]\n",
    "\n",
    "        # Only 2 loss functions needed for JMMD\n",
    "        loss_fn = [loss_fn_ce, loss_fn_bce]\n",
    "    \n",
    "        ##########################\n",
    "        if epoch in [int(n_epochs * r) for r in [0, 0.25, 0.5, 0.75]] or epoch == n_epochs-1:\n",
    "            # return_features == return features to calculate PAD\n",
    "            return_features = True\n",
    "            epoc_pad.append(epoch)\n",
    "        else:\n",
    "            return_features = False\n",
    "\n",
    "        ##########################\n",
    "        # \n",
    "        train_step_output = train_step_wgan_gp_source_only(model, loader_H, loss_fn, optimizer, lower_range=-1, \n",
    "                        save_features=return_features, weights=weights, linear_interp=linear_interp)\n",
    "\n",
    "        train_epoc_loss_est        = train_step_output.avg_epoc_loss_est\n",
    "        train_epoc_loss_d          = train_step_output.avg_epoc_loss_d\n",
    "        train_epoc_loss_domain     = train_step_output.avg_epoc_loss_domain  # Now contains JMMD loss\n",
    "        train_epoc_loss            = train_step_output.avg_epoc_loss\n",
    "        train_epoc_loss_est_target = train_step_output.avg_epoc_loss_est_target\n",
    "                # train_epoc_loss        = total train loss = loss_est + lambda_jmmd * jmmd_loss\n",
    "                # train_epoc_loss_est    = loss in estimation network in source domain (labels available)\n",
    "                # train_epoc_loss_domain = JMMD loss (statistical distribution matching)\n",
    "                # train_epoc_loss_est_target - just to monitor - the machine can not calculate because no label available in source domain\n",
    "                # All are already calculated in average over training dataset (source/target - respectively)\n",
    "        print(\"Time\", time.perf_counter() - start, \"seconds\")\n",
    "        # Note: No PAD calculation for source-only training since we're not doing domain adaptation\n",
    "            \n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        train_metrics['train_loss'].append(train_epoc_loss)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Training Loss: {train_epoc_loss:.6f}\")\n",
    "        \n",
    "        train_metrics['train_est_loss'].append(train_epoc_loss_est)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Estimation Loss (in Source domain): {train_epoc_loss_est:.6f}\")\n",
    "        \n",
    "        train_metrics['train_disc_loss'].append(train_epoc_loss_d)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Average Disc Loss (in Source domain): {train_epoc_loss_d:.6f}\")\n",
    "        \n",
    "        train_metrics['train_domain_loss'].append(train_epoc_loss_domain)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Source-only training (No domain adaptation): {train_epoc_loss_domain:.6f}\")  # Updated print message\n",
    "        \n",
    "        train_metrics['train_est_loss_target'].append(train_epoc_loss_est_target)\n",
    "        print(f\"epoch {epoch+1}/{n_epochs} Testing performance on Target domain: {train_epoc_loss_est_target:.6f}\")\n",
    "        \n",
    "        \n",
    "        # ===================== Evaluation =====================\n",
    "        loader_H_true_val_source.reset()\n",
    "        loader_H_input_val_source.reset()\n",
    "        loader_H_true_val_target.reset()\n",
    "        loader_H_input_val_target.reset()\n",
    "        loader_H_eval = [loader_H_input_val_source, loader_H_true_val_source, loader_H_input_val_target, loader_H_true_val_target]\n",
    "\n",
    "        # \n",
    "        loss_fn = [loss_fn_ce, loss_fn_bce]\n",
    "        \n",
    "        # eval_func = utils_UDA_FiLM.val_step\n",
    "        if (epoch==epoch_min) or (epoch+1>epoch_min and (epoch-epoch_min)%epoch_step==0) or epoch==n_epochs-1:\n",
    "            # \n",
    "            H_sample, epoc_val_return = val_step_wgan_gp_source_only(model, loader_H_eval, loss_fn, lower_range, \n",
    "                                            weights=weights, linear_interp=linear_interp)\n",
    "            visualize_H(H_sample, H_to_save, epoch, plotfig.figChan, flag, model_path, sub_folder, domain_weight=0.0)\n",
    "            flag = 0  # after the first epoch, no need to save H_true anymore\n",
    "            \n",
    "        else:\n",
    "            # \n",
    "            _, epoc_val_return = val_step_wgan_gp_source_only(model, loader_H_eval, loss_fn, lower_range, \n",
    "                                        weights=weights, linear_interp=linear_interp)\n",
    "        \n",
    "        post_val(epoc_val_return, epoch, n_epochs, val_metrics, domain_weight=0.0)\n",
    "        \n",
    "        if (epoch==epoch_min) or (epoch+1>epoch_min and (epoch-epoch_min)%epoch_step==0) or epoch==n_epochs-1:\n",
    "            # \n",
    "            all_metrics = {\n",
    "                'figLoss': plotfig.figLoss, \n",
    "                'savemat': savemat,\n",
    "                'pad_metrics': pad_metrics, \n",
    "                'epoc_pad': epoc_pad,\n",
    "                'pad_svm': pad_svm, \n",
    "                'weights': weights, \n",
    "                'optimizer': optimizer\n",
    "            }\n",
    "            # Combine all metrics\n",
    "            all_metrics.update(train_metrics)  # Add training metrics\n",
    "            all_metrics.update(val_metrics)    # Add validation metrics\n",
    "\n",
    "            save_checkpoint(model, save_model, model_path, sub_folder, epoch, all_metrics)\n",
    "    \n",
    "    # end of epoch loop\n",
    "    # =====================            \n",
    "    # Save performances\n",
    "    # Save H matrix\n",
    "    savemat(model_path + '/' + sub_folder + '/H_visualize/H_trix.mat', H_to_save)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
